{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7vL/pq8z8nSMP6E4Ksqd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kathy42xu/DL_TA/blob/main/lstm_rf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGT4Z85izHxM",
        "outputId": "21462b07-65ba-4699-b7f1-74ddef48bff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: \n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.11/dist-packages (0.2.55)\n",
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.3.7)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.11/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.11/dist-packages (from yfinance) (3.17.9)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.11/dist-packages (from yfinance) (4.13.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (4.13.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.0->yfinance) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->yfinance) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.17.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=6b419e1b8001f55d536572bec662d573b0679600c97d3c1690658058d529e76f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/d7/29/7781cc5eb9a3659d032d7d15bdd0f49d07d2b24fec29f44bc4\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n",
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "# 启用 GPU\n",
        "import tensorflow as tf\n",
        "device = tf.test.gpu_device_name()\n",
        "print(\"GPU:\", device)\n",
        "\n",
        "# 安装依赖（若需要）\n",
        "!pip install yfinance ta\n",
        "\n",
        "# 下载数据 (示例：S&P500)\n",
        "import yfinance as yf\n",
        "df = yf.download(\"^GSPC\", start=\"2002-08-01\", end=\"2018-06-28\")\n",
        "df.to_csv(\"SP500.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprocessing_indicator"
      ],
      "metadata": {
        "id": "Ziu6Gpq503gK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1️⃣ 重新读取 CSV —— 明确告诉 pandas 用第一列作 index\n",
        "df = pd.read_csv(\"SP500.csv\", index_col=0, parse_dates=True)\n",
        "\n",
        "# 2️⃣ 确认列名正确，只保留 Open/High/Low/Close/Volume\n",
        "print(df.columns)\n",
        "df = df[['Open','High','Low','Close','Volume']]\n",
        "\n",
        "# 3️⃣ 强制转成浮点数（会把任何非数字变成 NaN）\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# 4️⃣ 删除因转换失败产生的 NaN 行\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWmMlDzy07aB",
        "outputId": "bfd5b18b-d762-40cc-906f-1c03e71e2f58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Close', 'High', 'Low', 'Open', 'Volume'], dtype='object')\n",
            "                  Open        High         Low       Close        Volume\n",
            "Price                                                                   \n",
            "2002-08-01  911.619995  911.619995  882.479980  884.659973  1.672200e+09\n",
            "2002-08-02  884.400024  884.719971  853.950012  864.239990  1.538100e+09\n",
            "2002-08-05  864.239990  864.239990  833.440002  834.599976  1.425500e+09\n",
            "2002-08-06  834.599976  874.440002  834.599976  859.570007  1.514100e+09\n",
            "2002-08-07  859.570007  878.739990  854.150024  876.770020  1.490400e+09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-dcf6b7282b58>:4: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df = pd.read_csv(\"SP500.csv\", index_col=0, parse_dates=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import ta\n",
        "\n",
        "# -------------------------------\n",
        "# 1) Read CSV with date parsing\n",
        "# -------------------------------\n",
        "df = pd.read_csv(\"SP500.csv\", index_col=0, parse_dates=True)\n",
        "\n",
        "# -------------------------------\n",
        "# 2) Keep only OHLCV and convert to float\n",
        "# -------------------------------\n",
        "df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "###############################################################################\n",
        "# 3) Compute 43 Technical Indicators (Computed Features)\n",
        "###############################################################################\n",
        "# We'll compute 43 computed indicators, so that with the 5 raw columns,\n",
        "# the final DataFrame has 43 + 5 = 48 columns.\n",
        "\n",
        "# (1) Standard Deviation over 20 days (SD_20)\n",
        "df['SD_20'] = df['Close'].rolling(20).std()\n",
        "\n",
        "# (2-4) Simple Moving Averages (SMA)\n",
        "df['SMA_5']  = ta.trend.sma_indicator(df['Close'], window=5)\n",
        "df['SMA_10'] = ta.trend.sma_indicator(df['Close'], window=10)\n",
        "df['SMA_20'] = ta.trend.sma_indicator(df['Close'], window=20)\n",
        "\n",
        "# (5-7) Exponential Moving Averages (EMA)\n",
        "df['EMA_6']  = ta.trend.ema_indicator(df['Close'], window=6)\n",
        "df['EMA_10'] = ta.trend.ema_indicator(df['Close'], window=10)\n",
        "df['EMA_14'] = ta.trend.ema_indicator(df['Close'], window=14)\n",
        "\n",
        "# (8) MACD with fast=6, slow=12\n",
        "df['MACD_6_12'] = ta.trend.macd_diff(df['Close'], window_slow=12, window_fast=6)\n",
        "\n",
        "# (9-10) Relative Strength Index (RSI)\n",
        "df['RSI_10'] = ta.momentum.rsi(df['Close'], window=10)\n",
        "df['RSI_14'] = ta.momentum.rsi(df['Close'], window=14)\n",
        "\n",
        "# (11) Commodity Channel Index (CCI)\n",
        "df['CCI_20'] = ta.trend.cci(df['High'], df['Low'], df['Close'], window=20)\n",
        "\n",
        "# (12-13) Bollinger Bands (Upper and Lower)\n",
        "df['BOLL_UB'] = ta.volatility.bollinger_hband(df['Close'], window=20)\n",
        "df['BOLL_LB'] = ta.volatility.bollinger_lband(df['Close'], window=20)\n",
        "\n",
        "# (14) Average True Range (ATR)\n",
        "df['ATR_14'] = ta.volatility.average_true_range(df['High'], df['Low'], df['Close'], window=14)\n",
        "\n",
        "# (15-18) True Range Components: H-L, H-Cp, L-Cp, TR\n",
        "df['H-L']  = df['High'] - df['Low']\n",
        "df['H-Cp'] = (df['High'] - df['Close'].shift(1)).abs()\n",
        "df['L-Cp'] = (df['Low']  - df['Close'].shift(1)).abs()\n",
        "df['TR']   = df[['H-L', 'H-Cp', 'L-Cp']].max(axis=1)\n",
        "\n",
        "# (19) On-Balance Volume (OBV)\n",
        "df['OBV'] = ta.volume.on_balance_volume(df['Close'], df['Volume'])\n",
        "\n",
        "# (20) Money Flow Index (MFI) using library\n",
        "df['MFI'] = ta.volume.money_flow_index(df['High'], df['Low'], df['Close'], df['Volume'], window=14)\n",
        "\n",
        "# (21) Force Index (1-day)\n",
        "df['ForceIndex'] = ta.volume.force_index(df['Close'], df['Volume'], window=1)\n",
        "# (22) 5-day Force Index (FI_5)\n",
        "df['FI_5'] = ta.volume.force_index(df['Close'], df['Volume'], window=5)\n",
        "\n",
        "# (23-24) Price and Volume Change Percentages (C%, V%)\n",
        "df['C%'] = (df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1)\n",
        "df['V%'] = (df['Volume'] - df['Volume'].shift(1)) / df['Volume'].shift(1)\n",
        "\n",
        "# (25) Negative Volume Index (NVI)\n",
        "df['NVI'] = ta.volume.negative_volume_index(df['Close'], df['Volume'])\n",
        "\n",
        "# (26) Ease of Movement (SEMV)\n",
        "df['SEMV'] = ta.volume.ease_of_movement(df['High'], df['Low'], df['Volume'])\n",
        "\n",
        "# (27) True Strength Index (TSI) – custom calculation\n",
        "def tsi(series, long=25, short=13):\n",
        "    diff = series.diff()\n",
        "    abs_diff = diff.abs()\n",
        "    ema1 = diff.ewm(span=long, adjust=False).mean()\n",
        "    ema2 = ema1.ewm(span=short, adjust=False).mean()\n",
        "    abs_ema1 = abs_diff.ewm(span=long, adjust=False).mean()\n",
        "    abs_ema2 = abs_ema1.ewm(span=short, adjust=False).mean()\n",
        "    return 100 * ema2 / abs_ema2\n",
        "\n",
        "df['TSI'] = tsi(df['Close'], long=25, short=13)\n",
        "\n",
        "# (28) Money Flow Ratio (MFR) – computed manually\n",
        "df['PMF'] = np.where(df['Close'] > df['Close'].shift(1), df['Close'] * df['Volume'], 0)\n",
        "df['NMF'] = np.where(df['Close'] < df['Close'].shift(1), df['Close'] * df['Volume'], 0)\n",
        "df['PMF_roll'] = df['PMF'].rolling(14).sum()\n",
        "df['NMF_roll'] = df['NMF'].rolling(14).sum()\n",
        "df['MFR'] = df['PMF_roll'] / df['NMF_roll']\n",
        "\n",
        "# (29) We'll include the library MFI as an additional indicator;\n",
        "#     This gives you two MFI-related features: MFI (from above) and a custom one.\n",
        "df['MFI_custom'] = 100 - (100 / (1 + df['MFR']))\n",
        "\n",
        "# (30-31) Vortex Indicators: Upper (UVI) and Lower (LVI)\n",
        "df['UVI'] = ta.trend.vortex_indicator_pos(df['High'], df['Low'], df['Close'], window=14)\n",
        "df['LVI'] = ta.trend.vortex_indicator_neg(df['High'], df['Low'], df['Close'], window=14)\n",
        "\n",
        "# (32-33) Know Sure Thing (KST) and its 9-day SMA signal (KST_9)\n",
        "df['KST'] = ta.trend.kst(df['Close'])\n",
        "df['KST_9'] = df['KST'].rolling(window=9).mean()\n",
        "\n",
        "# (34) Detrended Price Oscillator (DPO, 20-day)\n",
        "df['DPO_20'] = ta.trend.dpo(df['Close'], window=20)\n",
        "\n",
        "# (35) Directional Index (DX) computed from ADX+ and ADX-\n",
        "adx_pos_14 = ta.trend.adx_pos(df['High'], df['Low'], df['Close'], window=14)\n",
        "adx_neg_14 = ta.trend.adx_neg(df['High'], df['Low'], df['Close'], window=14)\n",
        "df['DX'] = 100 * (adx_pos_14 - adx_neg_14).abs() / (adx_pos_14 + adx_neg_14)\n",
        "\n",
        "# (36-37) Average Directional Index (ADX) for 7-day and 14-day\n",
        "df['ADX_7'] = ta.trend.adx(df['High'], df['Low'], df['Close'], window=7)\n",
        "df['ADX_14'] = ta.trend.adx(df['High'], df['Low'], df['Close'], window=14)\n",
        "\n",
        "# (38) Rate of Change (ROC, 12-day)\n",
        "df['ROC_12'] = ta.momentum.roc(df['Close'], window=12)\n",
        "\n",
        "# (39) Williams %R (with lookback period 14)\n",
        "df['Williams_%R'] = ta.momentum.williams_r(df['High'], df['Low'], df['Close'], lbp=14)\n",
        "\n",
        "# --- Extra 5 to reach 43 computed indicators ---\n",
        "\n",
        "# (40) EMA of Volume (10-day)\n",
        "df['EMA_Volume'] = ta.trend.ema_indicator(df['Volume'], window=10)\n",
        "\n",
        "# (41) Rate of Change (ROC, 5-day)\n",
        "df['ROC_5'] = ta.momentum.roc(df['Close'], window=5)\n",
        "\n",
        "# (42) Bollinger Bandwidth: (UB - LB) / SMA_20\n",
        "df['BOLL_BW'] = (df['BOLL_UB'] - df['BOLL_LB']) / df['SMA_20']\n",
        "\n",
        "# (43) ATR Ratio: ATR_14 divided by SMA_20\n",
        "df['ATR_Ratio'] = df['ATR_14'] / df['SMA_20']\n",
        "\n",
        "# (44) Volatility: Coefficient of Variation = SD_20 / SMA_20\n",
        "df['Vol_CV'] = df['SD_20'] / df['SMA_20']\n",
        "\n",
        "###############################################################################\n",
        "# Now, decide which computed indicators to keep.\n",
        "# We want exactly 43 computed indicators. Currently, after the raw OHLCV,\n",
        "# our DataFrame has extra intermediate columns.\n",
        "#\n",
        "# The current columns list (after computation) is:\n",
        "# ['Open', 'High', 'Low', 'Close', 'Volume', 'SD_20', 'SMA_5', 'SMA_10', 'SMA_20',\n",
        "#  'EMA_6', 'EMA_10', 'EMA_14', 'MACD_6_12', 'RSI_10', 'RSI_14', 'CCI_20',\n",
        "#  'BOLL_UB', 'BOLL_LB', 'ATR_14', 'H-L', 'H-Cp', 'L-Cp', 'TR', 'OBV', 'MFI',\n",
        "#  'ForceIndex', 'FI_5', 'C%', 'V%', 'NVI', 'SEMV', 'TSI', 'PMF', 'NMF', 'PMF_roll',\n",
        "#  'NMF_roll', 'MFR', 'MFI_custom', 'UVI', 'LVI', 'KST', 'KST_9', 'DPO_20', 'DX',\n",
        "#  'ADX_7', 'ADX_14', 'ROC_12', 'Williams_%R', 'EMA_Volume', 'ROC_5', 'BOLL_BW',\n",
        "#  'ATR_Ratio', 'Vol_CV']\n",
        "#\n",
        "# We need to select 43 computed features from these.\n",
        "#\n",
        "# One common choice (based on the paper's indicator list) is to keep:\n",
        "#    SMA_5, SMA_10, SMA_20,\n",
        "#    EMA_6, EMA_10, EMA_14,\n",
        "#    MACD_6_12,\n",
        "#    RSI_10, RSI_14,\n",
        "#    CCI_20,\n",
        "#    BOLL_UB, BOLL_LB,\n",
        "#    ATR_14,\n",
        "#    H-L, H-Cp, L-Cp, TR,\n",
        "#    OBV,\n",
        "#    MFI,            # (library version)\n",
        "#    ForceIndex, FI_5,\n",
        "#    C%, V%,\n",
        "#    NVI,\n",
        "#    SEMV,\n",
        "#    TSI,\n",
        "#    MFR,            # Money Flow Ratio\n",
        "#    UVI, LVI,\n",
        "#    KST, KST_9,\n",
        "#    DPO_20,\n",
        "#    DX,\n",
        "#    ADX_7, ADX_14,\n",
        "#    ROC_12,\n",
        "#    Williams_%R,\n",
        "#    EMA_Volume,     # extra\n",
        "#    ROC_5,          # extra\n",
        "#    BOLL_BW,        # extra\n",
        "#    ATR_Ratio,      # extra\n",
        "#    Vol_CV          # extra\n",
        "#\n",
        "# That is a total of 43 computed indicators.\n",
        "###############################################################################\n",
        "\n",
        "computed_features = ['SD_20','SMA_5', 'SMA_10', 'SMA_20',\n",
        "                     'EMA_6', 'EMA_10', 'EMA_14',\n",
        "                     'MACD_6_12',\n",
        "                     'RSI_10', 'RSI_14',\n",
        "                     'CCI_20',\n",
        "                     'BOLL_UB', 'BOLL_LB',\n",
        "                     'ATR_14',\n",
        "                     'H-L', 'H-Cp', 'L-Cp', 'TR',\n",
        "                     'OBV',\n",
        "                     'MFI',\n",
        "                     'ForceIndex', 'FI_5',\n",
        "                     'C%', 'V%',\n",
        "                     'NVI',\n",
        "                     'SEMV',\n",
        "                     'TSI',\n",
        "                     'MFR',\n",
        "                     'UVI', 'LVI',\n",
        "                     'KST', 'KST_9',\n",
        "                     'DPO_20',\n",
        "                     'DX',\n",
        "                     'ADX_7', 'ADX_14',\n",
        "                     'ROC_12',\n",
        "                     'Williams_%R',\n",
        "                     'EMA_Volume',\n",
        "                     'ROC_5',\n",
        "                     'BOLL_BW',\n",
        "                     'ATR_Ratio',\n",
        "                     'Vol_CV']\n",
        "\n",
        "# Now, the final DataFrame should contain the 5 raw columns + these 43 computed features.\n",
        "final_cols = ['Open', 'High', 'Low', 'Close', 'Volume'] + computed_features\n",
        "df_final = df[final_cols].copy()\n",
        "\n",
        "###############################################################################\n",
        "# 4) Normalization\n",
        "###############################################################################\n",
        "scaler = MinMaxScaler()\n",
        "df_final[final_cols] = scaler.fit_transform(df_final[final_cols])\n",
        "\n",
        "###############################################################################\n",
        "# 5) Construct 50-day supervised sequences\n",
        "###############################################################################\n",
        "window = 50\n",
        "# Compute next-day log returns (×100)\n",
        "returns = 100 * np.log(df_final['Close'] / df_final['Close'].shift(1))\n",
        "returns = returns.dropna()  # drop the first NaN row\n",
        "\n",
        "X, y_reg, y_clf = [], [], []\n",
        "for i in range(len(returns) - window):\n",
        "    seq = df_final.iloc[i : i+window].values  # shape: (50, 48)\n",
        "    X.append(seq)\n",
        "    ret_val = returns.iloc[i+window]\n",
        "    y_reg.append(ret_val)\n",
        "    y_clf.append(int(ret_val > 0))\n",
        "\n",
        "X = np.array(X)\n",
        "y_reg = np.array(y_reg)\n",
        "y_clf = np.array(y_clf)\n",
        "\n",
        "###############################################################################\n",
        "# 6) Save final dataset\n",
        "###############################################################################\n",
        "np.savez(\"SP500_preprocessed.npz\", X=X, y_reg=y_reg, y_clf=y_clf)\n",
        "\n",
        "print(\"Done!\")\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y_reg shape:\", y_reg.shape)\n",
        "print(\"y_clf shape:\", y_clf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO1VNKDgwnzP",
        "outputId": "60b9302c-645e-44bb-b0da-72c9124c416c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-95c388c57979>:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df = pd.read_csv(\"SP500.csv\", index_col=0, parse_dates=True)\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n",
            "X shape: (3954, 50, 48)\n",
            "y_reg shape: (3954,)\n",
            "y_clf shape: (3954,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train LSTM"
      ],
      "metadata": {
        "id": "hR35v7XbyhnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = np.load(\"SP500_preprocessed.npz\")\n",
        "X, y_reg, y_clf = data['X'], data['y_reg'], data['y_clf']\n",
        "\n",
        "# 按 70% train / 10% validation / 20% test 切分\n",
        "X_temp, X_test, y_reg_temp, y_reg_test, y_clf_temp, y_clf_test = train_test_split(\n",
        "    X, y_reg, y_clf, test_size=0.2, shuffle=False)\n",
        "\n",
        "X_train, X_val, y_reg_train, y_reg_val, y_clf_train, y_clf_val = train_test_split(\n",
        "    X_temp, y_reg_temp, y_clf_temp, test_size=0.125, shuffle=False)\n",
        "\n",
        "print(\"Shapes → Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WDNkV-gypcX",
        "outputId": "d7901088-3733-40f9-d7e7-46de5e4b4e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes → Train: (2767, 50, 48) Val: (396, 50, 48) Test: (791, 50, 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = (~np.isnan(y_reg)) & (~np.isinf(y_reg))\n",
        "X, y_reg, y_clf = X[mask], y_reg[mask], y_clf[mask]\n"
      ],
      "metadata": {
        "id": "U1oZ5rpxzHra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LFM"
      ],
      "metadata": {
        "id": "k8URpXWHyuSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Split data exactly as authors do\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_temp, X_test, y_reg_temp, y_reg_test, y_clf_temp, y_clf_test = train_test_split(X, y_reg, y_clf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, y_reg_train, y_reg_val, y_clf_train, y_clf_val = train_test_split(X_temp, y_reg_temp, y_clf_temp, test_size=0.125, shuffle=False)\n",
        "\n",
        "# 2️⃣ Build exactly as original script\n",
        "def build_model():\n",
        "    inp = Input(shape=(50, X.shape[2]))\n",
        "    x = LSTM(15, return_sequences=False)(inp)\n",
        "    x = Dense(30, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(30, activation=\"relu\")(x)\n",
        "    out_reg = Dense(1, name=\"regression\")(x)\n",
        "    out_clf = Dense(2, activation=\"softmax\", name=\"classification\")(x)\n",
        "    model = Model(inp, [out_reg, out_clf])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss={\"regression\":\"mse\", \"classification\":\"sparse_categorical_crossentropy\"},\n",
        "        loss_weights={\"regression\":0.1, \"classification\":1.0}\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "\n",
        "# 3️⃣ Validate no NaNs in training batches\n",
        "print(\"Train X NaNs:\", np.isnan(X_train).sum(), \"y_reg NaNs:\", np.isnan(y_reg_train).sum())\n",
        "\n",
        "# 4️⃣ Train\n",
        "history = model.fit(\n",
        "    X_train, {\"regression\":y_reg_train, \"classification\":y_clf_train},\n",
        "    validation_data=(X_val, {\"regression\":y_reg_val, \"classification\":y_clf_val}),\n",
        "    batch_size=256, epochs=300, callbacks=[EarlyStopping(patience=20, restore_best_weights=True)]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKCjX-HEyvfb",
        "outputId": "cc778200-897a-482d-ccee-119336cadf97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train X NaNs: 0 y_reg NaNs: 0\n",
            "Epoch 1/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 92ms/step - classification_loss: 0.6887 - loss: 5.0865 - regression_loss: 43.8788 - val_classification_loss: 0.6907 - val_loss: 0.8137 - val_regression_loss: 1.2653\n",
            "Epoch 2/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6914 - loss: 5.1222 - regression_loss: 44.2889 - val_classification_loss: 0.6910 - val_loss: 0.8129 - val_regression_loss: 1.2580\n",
            "Epoch 3/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6890 - loss: 4.1000 - regression_loss: 34.0164 - val_classification_loss: 0.6914 - val_loss: 0.8134 - val_regression_loss: 1.2609\n",
            "Epoch 4/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6871 - loss: 3.7978 - regression_loss: 30.9953 - val_classification_loss: 0.6912 - val_loss: 0.8128 - val_regression_loss: 1.2579\n",
            "Epoch 5/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - classification_loss: 0.6905 - loss: 3.1821 - regression_loss: 25.5191 - val_classification_loss: 0.6908 - val_loss: 0.8125 - val_regression_loss: 1.2550\n",
            "Epoch 6/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - classification_loss: 0.6891 - loss: 4.6058 - regression_loss: 39.0919 - val_classification_loss: 0.6908 - val_loss: 0.8124 - val_regression_loss: 1.2557\n",
            "Epoch 7/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - classification_loss: 0.6898 - loss: 3.3434 - regression_loss: 26.4177 - val_classification_loss: 0.6910 - val_loss: 0.8129 - val_regression_loss: 1.2619\n",
            "Epoch 8/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - classification_loss: 0.6910 - loss: 4.1591 - regression_loss: 34.6381 - val_classification_loss: 0.6914 - val_loss: 0.8137 - val_regression_loss: 1.2672\n",
            "Epoch 9/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6890 - loss: 4.2982 - regression_loss: 35.9731 - val_classification_loss: 0.6912 - val_loss: 0.8140 - val_regression_loss: 1.2705\n",
            "Epoch 10/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - classification_loss: 0.6874 - loss: 4.0606 - regression_loss: 34.4244 - val_classification_loss: 0.6912 - val_loss: 0.8132 - val_regression_loss: 1.2627\n",
            "Epoch 11/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - classification_loss: 0.6881 - loss: 5.1969 - regression_loss: 45.0316 - val_classification_loss: 0.6912 - val_loss: 0.8127 - val_regression_loss: 1.2558\n",
            "Epoch 12/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6875 - loss: 3.3120 - regression_loss: 26.8937 - val_classification_loss: 0.6913 - val_loss: 0.8126 - val_regression_loss: 1.2557\n",
            "Epoch 13/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6915 - loss: 5.1771 - regression_loss: 44.8521 - val_classification_loss: 0.6911 - val_loss: 0.8130 - val_regression_loss: 1.2588\n",
            "Epoch 14/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - classification_loss: 0.6883 - loss: 4.1348 - regression_loss: 34.4424 - val_classification_loss: 0.6921 - val_loss: 0.8136 - val_regression_loss: 1.2604\n",
            "Epoch 15/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - classification_loss: 0.6874 - loss: 6.4119 - regression_loss: 57.1726 - val_classification_loss: 0.6914 - val_loss: 0.8136 - val_regression_loss: 1.2652\n",
            "Epoch 16/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6888 - loss: 3.6089 - regression_loss: 29.3186 - val_classification_loss: 0.6911 - val_loss: 0.8133 - val_regression_loss: 1.2654\n",
            "Epoch 17/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6891 - loss: 3.1247 - regression_loss: 25.0110 - val_classification_loss: 0.6914 - val_loss: 0.8132 - val_regression_loss: 1.2633\n",
            "Epoch 18/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6867 - loss: 6.9737 - regression_loss: 62.8267 - val_classification_loss: 0.6919 - val_loss: 0.8134 - val_regression_loss: 1.2601\n",
            "Epoch 19/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6879 - loss: 6.4605 - regression_loss: 57.6519 - val_classification_loss: 0.6915 - val_loss: 0.8131 - val_regression_loss: 1.2595\n",
            "Epoch 20/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6884 - loss: 3.5646 - regression_loss: 28.6579 - val_classification_loss: 0.6910 - val_loss: 0.8126 - val_regression_loss: 1.2591\n",
            "Epoch 21/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6886 - loss: 3.4917 - regression_loss: 28.0141 - val_classification_loss: 0.6910 - val_loss: 0.8129 - val_regression_loss: 1.2612\n",
            "Epoch 22/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - classification_loss: 0.6866 - loss: 4.3437 - regression_loss: 36.5807 - val_classification_loss: 0.6912 - val_loss: 0.8125 - val_regression_loss: 1.2591\n",
            "Epoch 23/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - classification_loss: 0.6888 - loss: 4.4119 - regression_loss: 37.2597 - val_classification_loss: 0.6910 - val_loss: 0.8119 - val_regression_loss: 1.2546\n",
            "Epoch 24/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - classification_loss: 0.6875 - loss: 6.0206 - regression_loss: 53.2372 - val_classification_loss: 0.6913 - val_loss: 0.8119 - val_regression_loss: 1.2518\n",
            "Epoch 25/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - classification_loss: 0.6891 - loss: 3.7243 - regression_loss: 30.2976 - val_classification_loss: 0.6912 - val_loss: 0.8119 - val_regression_loss: 1.2528\n",
            "Epoch 26/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6878 - loss: 4.2230 - regression_loss: 35.2664 - val_classification_loss: 0.6908 - val_loss: 0.8114 - val_regression_loss: 1.2512\n",
            "Epoch 27/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6870 - loss: 5.6234 - regression_loss: 49.2712 - val_classification_loss: 0.6908 - val_loss: 0.8113 - val_regression_loss: 1.2509\n",
            "Epoch 28/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6893 - loss: 3.9442 - regression_loss: 32.5259 - val_classification_loss: 0.6903 - val_loss: 0.8109 - val_regression_loss: 1.2487\n",
            "Epoch 29/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - classification_loss: 0.6881 - loss: 5.8301 - regression_loss: 51.3123 - val_classification_loss: 0.6909 - val_loss: 0.8116 - val_regression_loss: 1.2517\n",
            "Epoch 30/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6863 - loss: 3.8881 - regression_loss: 31.9848 - val_classification_loss: 0.6906 - val_loss: 0.8115 - val_regression_loss: 1.2514\n",
            "Epoch 31/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - classification_loss: 0.6891 - loss: 3.8088 - regression_loss: 31.1461 - val_classification_loss: 0.6909 - val_loss: 0.8114 - val_regression_loss: 1.2508\n",
            "Epoch 32/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6876 - loss: 5.0761 - regression_loss: 43.9911 - val_classification_loss: 0.6905 - val_loss: 0.8110 - val_regression_loss: 1.2494\n",
            "Epoch 33/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - classification_loss: 0.6883 - loss: 3.3070 - regression_loss: 26.0859 - val_classification_loss: 0.6904 - val_loss: 0.8109 - val_regression_loss: 1.2482\n",
            "Epoch 34/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - classification_loss: 0.6894 - loss: 3.5704 - regression_loss: 28.9140 - val_classification_loss: 0.6905 - val_loss: 0.8112 - val_regression_loss: 1.2489\n",
            "Epoch 35/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - classification_loss: 0.6864 - loss: 3.7921 - regression_loss: 31.1325 - val_classification_loss: 0.6910 - val_loss: 0.8115 - val_regression_loss: 1.2517\n",
            "Epoch 36/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - classification_loss: 0.6904 - loss: 3.8431 - regression_loss: 31.4688 - val_classification_loss: 0.6913 - val_loss: 0.8116 - val_regression_loss: 1.2489\n",
            "Epoch 37/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6876 - loss: 3.6556 - regression_loss: 30.2937 - val_classification_loss: 0.6914 - val_loss: 0.8116 - val_regression_loss: 1.2481\n",
            "Epoch 38/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6885 - loss: 3.6961 - regression_loss: 30.0330 - val_classification_loss: 0.6911 - val_loss: 0.8118 - val_regression_loss: 1.2505\n",
            "Epoch 39/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6864 - loss: 3.3786 - regression_loss: 26.9627 - val_classification_loss: 0.6915 - val_loss: 0.8122 - val_regression_loss: 1.2517\n",
            "Epoch 40/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6894 - loss: 3.5890 - regression_loss: 28.8805 - val_classification_loss: 0.6913 - val_loss: 0.8126 - val_regression_loss: 1.2563\n",
            "Epoch 41/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6870 - loss: 4.1408 - regression_loss: 34.5387 - val_classification_loss: 0.6905 - val_loss: 0.8114 - val_regression_loss: 1.2505\n",
            "Epoch 42/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - classification_loss: 0.6849 - loss: 3.6998 - regression_loss: 30.1083 - val_classification_loss: 0.6904 - val_loss: 0.8115 - val_regression_loss: 1.2491\n",
            "Epoch 43/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - classification_loss: 0.6884 - loss: 4.6622 - regression_loss: 39.6828 - val_classification_loss: 0.6906 - val_loss: 0.8118 - val_regression_loss: 1.2479\n",
            "Epoch 44/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - classification_loss: 0.6899 - loss: 6.2683 - regression_loss: 55.9194 - val_classification_loss: 0.6904 - val_loss: 0.8112 - val_regression_loss: 1.2449\n",
            "Epoch 45/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - classification_loss: 0.6894 - loss: 5.4581 - regression_loss: 47.5690 - val_classification_loss: 0.6905 - val_loss: 0.8111 - val_regression_loss: 1.2444\n",
            "Epoch 46/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6867 - loss: 3.4247 - regression_loss: 27.6107 - val_classification_loss: 0.6904 - val_loss: 0.8110 - val_regression_loss: 1.2460\n",
            "Epoch 47/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6860 - loss: 3.9758 - regression_loss: 32.7909 - val_classification_loss: 0.6904 - val_loss: 0.8112 - val_regression_loss: 1.2457\n",
            "Epoch 48/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - classification_loss: 0.6866 - loss: 4.8617 - regression_loss: 41.6355 - val_classification_loss: 0.6907 - val_loss: 0.8117 - val_regression_loss: 1.2488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## paper logic:100 LSTM base model + learning rate halved every 50 epochs + 300 epochs fixed training + 13 randomly drawn features + bootstrap samples + final average prediction\n"
      ],
      "metadata": {
        "id": "8ObU0YAi0zR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.models import clone_model\n",
        "\n",
        "def build_model(input_dim):\n",
        "    inp = Input(shape=(50, input_dim))\n",
        "    x = LSTM(15)(inp)\n",
        "    x = Dense(30, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(30, activation=\"relu\")(x)\n",
        "    out_reg = Dense(1, name=\"regression\")(x)\n",
        "    out_clf = Dense(2, activation=\"softmax\", name=\"classification\")(x)\n",
        "    model = Model(inp, [out_reg, out_clf])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss={\"regression\":\"mse\", \"classification\":\"sparse_categorical_crossentropy\"},\n",
        "        loss_weights={\"regression\":0.1, \"classification\":1.0}\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Learning rate schedule: halve every 50 epochs\n",
        "def lr_schedule(epoch):\n",
        "    return 1e-3 * (0.5 ** (epoch // 50))\n",
        "\n",
        "lr_cb = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "ensemble_preds_reg = []\n",
        "ensemble_preds_clf = []\n",
        "\n",
        "for i in range(100):\n",
        "    # Randomly sample 13 features\n",
        "    features_idx = random.sample(range(X_train.shape[2]), 13)\n",
        "    X_tr_sub = X_train[:,:,features_idx]\n",
        "    X_val_sub = X_val[:,:,features_idx]\n",
        "    X_test_sub = X_test[:,:,features_idx]\n",
        "\n",
        "    # Bootstrap sample training data\n",
        "    idx = np.random.choice(len(X_tr_sub), size=len(X_tr_sub), replace=True)\n",
        "    X_boot, y_reg_boot, y_clf_boot = X_tr_sub[idx], y_reg_train[idx], y_clf_train[idx]\n",
        "\n",
        "    # Build & train\n",
        "    model_i = build_model(input_dim=X_train.shape[2] if False else X_boot.shape[2])\n",
        "    model_i.fit(\n",
        "        X_boot, {\"regression\": y_reg_boot, \"classification\": y_clf_boot},\n",
        "        validation_data=(X_val_sub, {\"regression\": y_reg_val, \"classification\": y_clf_val}),\n",
        "        epochs=300, batch_size=256, callbacks=[lr_cb], verbose=0\n",
        "    )\n",
        "\n",
        "    # Predict on test\n",
        "    reg_pred, clf_pred = model_i.predict(X_test_sub, verbose=0)\n",
        "    ensemble_preds_reg.append(reg_pred.flatten())\n",
        "    ensemble_preds_clf.append(clf_pred)\n",
        "\n",
        "# Average ensemble outputs\n",
        "final_reg = np.mean(np.vstack(ensemble_preds_reg), axis=0)\n",
        "final_clf = np.mean(np.stack(ensemble_preds_clf), axis=0).argmax(axis=1)\n",
        "\n",
        "print(\"Ensemble Test RMSE:\", np.sqrt(((final_reg - y_reg_test)**2).mean()))\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "print(\"Ensemble Test BACC:\", balanced_accuracy_score(y_clf_test, final_clf))\n"
      ],
      "metadata": {
        "id": "Eex-ZZcv0-tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#multi task\n"
      ],
      "metadata": {
        "id": "ZpK-bFNIEH9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# --- Assume df_final has been created as in your preprocessing cell ---\n",
        "# final_cols = ['Open','High','Low','Close','Volume'] + computed_features\n",
        "# df_final = df[final_cols].copy()\n",
        "\n",
        "# Check if any NaNs remain in df_final\n",
        "print(\"NaNs per column in final DataFrame:\")\n",
        "print(df_final.isna().sum())\n",
        "\n",
        "# Normalize the final DataFrame\n",
        "scaler = MinMaxScaler()\n",
        "final_cols = df_final.columns.tolist()\n",
        "df_final[final_cols] = scaler.fit_transform(df_final[final_cols])\n",
        "\n",
        "# Compute next-day log returns and drop the first row\n",
        "returns = 100 * np.log(df_final['Close'] / df_final['Close'].shift(1))\n",
        "returns = returns.dropna()\n",
        "\n",
        "# Construct 50-day sequences\n",
        "window = 50\n",
        "X, y_reg, y_clf = [], [], []\n",
        "for i in range(len(returns) - window):\n",
        "    seq = df_final.iloc[i : i+window].values  # each seq: shape (50, 48)\n",
        "    X.append(seq)\n",
        "    ret_val = returns.iloc[i+window]\n",
        "    y_reg.append(ret_val)\n",
        "    y_clf.append(int(ret_val > 0))\n",
        "\n",
        "X = np.array(X)\n",
        "y_reg = np.array(y_reg)\n",
        "y_clf = np.array(y_clf)\n",
        "\n",
        "print(\"Before filtering, X shape:\", X.shape)\n",
        "\n",
        "# Filter out any sequences that contain NaN values\n",
        "valid_mask = ~np.isnan(X).any(axis=(1, 2))\n",
        "X = X[valid_mask]\n",
        "y_reg = y_reg[valid_mask]\n",
        "y_clf = y_clf[valid_mask]\n",
        "\n",
        "print(\"After filtering, X shape:\", X.shape)\n",
        "print(\"y_reg shape:\", y_reg.shape, \"y_clf shape:\", y_clf.shape)\n",
        "\n",
        "# Save the dataset\n",
        "np.savez(\"SP500_preprocessed.npz\", X=X, y_reg=y_reg, y_clf=y_clf)\n",
        "print(\"Dataset saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEY1Gmu1JVSn",
        "outputId": "ef01540a-0c50-430c-8439-fa815eb2ec25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaNs per column in final DataFrame:\n",
            "Open            0\n",
            "High            0\n",
            "Low             0\n",
            "Close           0\n",
            "Volume          0\n",
            "SD_20          19\n",
            "SMA_5           4\n",
            "SMA_10          9\n",
            "SMA_20         19\n",
            "EMA_6           5\n",
            "EMA_10          9\n",
            "EMA_14         13\n",
            "MACD_6_12      19\n",
            "RSI_10          9\n",
            "RSI_14         13\n",
            "CCI_20         19\n",
            "BOLL_UB        19\n",
            "BOLL_LB        19\n",
            "ATR_14          0\n",
            "H-L             0\n",
            "H-Cp            1\n",
            "L-Cp            1\n",
            "TR              0\n",
            "OBV             0\n",
            "MFI            13\n",
            "ForceIndex      1\n",
            "FI_5            5\n",
            "C%              1\n",
            "V%              1\n",
            "NVI             0\n",
            "SEMV            1\n",
            "TSI             1\n",
            "MFR            13\n",
            "UVI            14\n",
            "LVI            14\n",
            "KST            14\n",
            "KST_9          22\n",
            "DPO_20         19\n",
            "DX             15\n",
            "ADX_7           0\n",
            "ADX_14          0\n",
            "ROC_12         12\n",
            "Williams_%R    13\n",
            "EMA_Volume      9\n",
            "ROC_5           5\n",
            "BOLL_BW        19\n",
            "ATR_Ratio      19\n",
            "Vol_CV         19\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before filtering, X shape: (3954, 50, 48)\n",
            "After filtering, X shape: (3932, 50, 48)\n",
            "y_reg shape: (3932,) y_clf shape: (3932,)\n",
            "Dataset saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, balanced_accuracy_score\n",
        "\n",
        "# ------------------------------\n",
        "# 1) Load the preprocessed dataset\n",
        "# ------------------------------\n",
        "data = np.load(\"SP500_preprocessed.npz\")\n",
        "X, y_reg, y_clf = data['X'], data['y_reg'], data['y_clf']\n",
        "\n",
        "# ------------------------------\n",
        "# 2) Data Cleaning (as in one-task version)\n",
        "# ------------------------------\n",
        "# Remove any samples with NaN or Inf in regression targets\n",
        "mask = (~np.isnan(y_reg)) & (~np.isinf(y_reg))\n",
        "X, y_reg, y_clf = X[mask], y_reg[mask], y_clf[mask]\n",
        "# Optionally clip extreme regression targets to avoid instability\n",
        "y_reg = np.clip(y_reg, -10, 10)\n",
        "\n",
        "# ------------------------------\n",
        "# 3) Split data exactly as authors do:\n",
        "#    70% train / 10% validation / 20% test (no shuffling)\n",
        "# ------------------------------\n",
        "X_temp, X_test, y_reg_temp, y_reg_test, y_clf_temp, y_clf_test = train_test_split(\n",
        "    X, y_reg, y_clf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, y_reg_train, y_reg_val, y_clf_train, y_clf_val = train_test_split(\n",
        "    X_temp, y_reg_temp, y_clf_temp, test_size=0.125, shuffle=False)\n",
        "\n",
        "print(\"Shapes → Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# ------------------------------\n",
        "# 4) Build the multitask LSTM model exactly as in your one-task version\n",
        "# ------------------------------\n",
        "def build_model():\n",
        "    inp = Input(shape=(50, X.shape[2]))  # X.shape[2] should be 48 (5 raw + 43 computed)\n",
        "    x = LSTM(15, return_sequences=False)(inp)\n",
        "    x = Dense(30, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(30, activation=\"relu\")(x)\n",
        "    out_reg = Dense(1, name=\"regression\")(x)\n",
        "    out_clf = Dense(2, activation=\"softmax\", name=\"classification\")(x)\n",
        "    model = Model(inputs=inp, outputs=[out_reg, out_clf])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss={\"regression\": \"mse\", \"classification\": \"sparse_categorical_crossentropy\"},\n",
        "                  loss_weights={\"regression\": 0.1, \"classification\": 1.0})\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "# Verify that training data has no NaNs\n",
        "print(\"Train X NaNs:\", np.isnan(X_train).sum(), \"y_reg NaNs:\", np.isnan(y_reg_train).sum())\n",
        "\n",
        "# ------------------------------\n",
        "# 5) Define learning rate schedule and early stopping\n",
        "# ------------------------------\n",
        "def lr_schedule(epoch, lr):\n",
        "    # Halve the learning rate every 50 epochs\n",
        "    return 1e-3 * (0.5 ** (epoch // 50))\n",
        "\n",
        "lr_cb = LearningRateScheduler(lr_schedule)\n",
        "es_cb = EarlyStopping(patience=20, restore_best_weights=True)\n",
        "\n",
        "# ------------------------------\n",
        "# 6) Train the model\n",
        "# ------------------------------\n",
        "history = model.fit(\n",
        "    X_train, {\"regression\": y_reg_train, \"classification\": y_clf_train},\n",
        "    validation_data=(X_val, {\"regression\": y_reg_val, \"classification\": y_clf_val}),\n",
        "    epochs=300,\n",
        "    batch_size=256,\n",
        "    callbacks=[lr_cb, es_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 7) Evaluate the model on the test set\n",
        "# ------------------------------\n",
        "pred_reg, pred_clf = model.predict(X_test, verbose=0)\n",
        "pred_clf = pred_clf.argmax(axis=1)\n",
        "\n",
        "rmse = math.sqrt(mean_squared_error(y_reg_test, pred_reg))\n",
        "acc = accuracy_score(y_clf_test, pred_clf)\n",
        "bacc = balanced_accuracy_score(y_clf_test, pred_clf)\n",
        "\n",
        "print(\"Test RMSE:\", rmse)\n",
        "print(\"Test Accuracy:\", acc)\n",
        "print(\"Test Balanced Accuracy:\", bacc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cz4nTly0JeQo",
        "outputId": "46225d34-d40e-4437-89c7-13ff691e7afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes → Train: (2751, 50, 48) Val: (393, 50, 48) Test: (786, 50, 48)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │          \u001b[38;5;34m3,840\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m480\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ regression (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m31\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ classification (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m62\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ regression (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ classification (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,343\u001b[0m (20.87 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,343</span> (20.87 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,343\u001b[0m (20.87 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,343</span> (20.87 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train X NaNs: 0 y_reg NaNs: 0\n",
            "Epoch 1/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 90ms/step - classification_loss: 0.6903 - loss: 1.6974 - regression_loss: 10.0700 - val_classification_loss: 0.6921 - val_loss: 0.8132 - val_regression_loss: 1.2572 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6896 - loss: 1.6389 - regression_loss: 9.4846 - val_classification_loss: 0.6918 - val_loss: 0.8133 - val_regression_loss: 1.2583 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6904 - loss: 1.6894 - regression_loss: 9.9900 - val_classification_loss: 0.6919 - val_loss: 0.8132 - val_regression_loss: 1.2566 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6905 - loss: 1.6520 - regression_loss: 9.6083 - val_classification_loss: 0.6922 - val_loss: 0.8131 - val_regression_loss: 1.2556 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6867 - loss: 1.6990 - regression_loss: 10.1209 - val_classification_loss: 0.6926 - val_loss: 0.8134 - val_regression_loss: 1.2562 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6894 - loss: 1.6321 - regression_loss: 9.4397 - val_classification_loss: 0.6914 - val_loss: 0.8125 - val_regression_loss: 1.2538 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - classification_loss: 0.6888 - loss: 1.7074 - regression_loss: 10.1790 - val_classification_loss: 0.6904 - val_loss: 0.8127 - val_regression_loss: 1.2645 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - classification_loss: 0.6887 - loss: 1.6091 - regression_loss: 9.2052 - val_classification_loss: 0.6902 - val_loss: 0.8117 - val_regression_loss: 1.2573 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - classification_loss: 0.6870 - loss: 1.6152 - regression_loss: 9.2853 - val_classification_loss: 0.6898 - val_loss: 0.8114 - val_regression_loss: 1.2582 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6876 - loss: 1.6543 - regression_loss: 9.6673 - val_classification_loss: 0.6903 - val_loss: 0.8125 - val_regression_loss: 1.2661 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - classification_loss: 0.6870 - loss: 1.6573 - regression_loss: 9.7105 - val_classification_loss: 0.6903 - val_loss: 0.8120 - val_regression_loss: 1.2610 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6885 - loss: 1.7154 - regression_loss: 10.2580 - val_classification_loss: 0.6907 - val_loss: 0.8134 - val_regression_loss: 1.2722 - learning_rate: 0.0010\n",
            "Epoch 13/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - classification_loss: 0.6877 - loss: 1.7024 - regression_loss: 10.1419 - val_classification_loss: 0.6905 - val_loss: 0.8147 - val_regression_loss: 1.2859 - learning_rate: 0.0010\n",
            "Epoch 14/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - classification_loss: 0.6888 - loss: 1.6616 - regression_loss: 9.7337 - val_classification_loss: 0.6918 - val_loss: 0.8156 - val_regression_loss: 1.2868 - learning_rate: 0.0010\n",
            "Epoch 15/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - classification_loss: 0.6886 - loss: 1.6409 - regression_loss: 9.5258 - val_classification_loss: 0.6919 - val_loss: 0.8145 - val_regression_loss: 1.2736 - learning_rate: 0.0010\n",
            "Epoch 16/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6882 - loss: 1.6237 - regression_loss: 9.3602 - val_classification_loss: 0.6914 - val_loss: 0.8175 - val_regression_loss: 1.3071 - learning_rate: 0.0010\n",
            "Epoch 17/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6872 - loss: 1.6759 - regression_loss: 9.8815 - val_classification_loss: 0.6904 - val_loss: 0.8148 - val_regression_loss: 1.2887 - learning_rate: 0.0010\n",
            "Epoch 18/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6878 - loss: 1.6158 - regression_loss: 9.2808 - val_classification_loss: 0.6909 - val_loss: 0.8161 - val_regression_loss: 1.2965 - learning_rate: 0.0010\n",
            "Epoch 19/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6870 - loss: 1.6811 - regression_loss: 9.9292 - val_classification_loss: 0.6910 - val_loss: 0.8171 - val_regression_loss: 1.3085 - learning_rate: 0.0010\n",
            "Epoch 20/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6860 - loss: 1.6484 - regression_loss: 9.6301 - val_classification_loss: 0.6917 - val_loss: 0.8213 - val_regression_loss: 1.3486 - learning_rate: 0.0010\n",
            "Epoch 21/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6859 - loss: 1.6843 - regression_loss: 9.9734 - val_classification_loss: 0.6915 - val_loss: 0.8207 - val_regression_loss: 1.3460 - learning_rate: 0.0010\n",
            "Epoch 22/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - classification_loss: 0.6882 - loss: 1.6340 - regression_loss: 9.4655 - val_classification_loss: 0.6912 - val_loss: 0.8155 - val_regression_loss: 1.2933 - learning_rate: 0.0010\n",
            "Epoch 23/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6843 - loss: 1.6579 - regression_loss: 9.7437 - val_classification_loss: 0.6913 - val_loss: 0.8185 - val_regression_loss: 1.3239 - learning_rate: 0.0010\n",
            "Epoch 24/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6887 - loss: 1.7186 - regression_loss: 10.2921 - val_classification_loss: 0.6919 - val_loss: 0.8188 - val_regression_loss: 1.3202 - learning_rate: 0.0010\n",
            "Epoch 25/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6881 - loss: 1.6952 - regression_loss: 10.0792 - val_classification_loss: 0.6920 - val_loss: 0.8191 - val_regression_loss: 1.3211 - learning_rate: 0.0010\n",
            "Epoch 26/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - classification_loss: 0.6924 - loss: 1.6856 - regression_loss: 9.9306 - val_classification_loss: 0.6918 - val_loss: 0.8158 - val_regression_loss: 1.2874 - learning_rate: 0.0010\n",
            "Epoch 27/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - classification_loss: 0.6894 - loss: 1.6696 - regression_loss: 9.8027 - val_classification_loss: 0.6922 - val_loss: 0.8171 - val_regression_loss: 1.3000 - learning_rate: 0.0010\n",
            "Epoch 28/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - classification_loss: 0.6891 - loss: 1.6955 - regression_loss: 10.0641 - val_classification_loss: 0.6920 - val_loss: 0.8190 - val_regression_loss: 1.3220 - learning_rate: 0.0010\n",
            "Epoch 29/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - classification_loss: 0.6866 - loss: 1.6243 - regression_loss: 9.3890 - val_classification_loss: 0.6919 - val_loss: 0.8179 - val_regression_loss: 1.3149 - learning_rate: 0.0010\n",
            "Test RMSE: 1.201570712689195\n",
            "Test Accuracy: 0.5330788804071247\n",
            "Test Balanced Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, balanced_accuracy_score\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1) Load preprocessed dataset\n",
        "# --------------------------------------------------\n",
        "data = np.load(\"SP500_preprocessed.npz\")\n",
        "X, y_reg, y_clf = data['X'], data['y_reg'], data['y_clf']\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2) Clean the data (same as one-task version)\n",
        "# --------------------------------------------------\n",
        "mask = (~np.isnan(y_reg)) & (~np.isinf(y_reg))\n",
        "X, y_reg, y_clf = X[mask], y_reg[mask], y_clf[mask]\n",
        "# Clip regression targets to a reasonable range (e.g., [-10, 10])\n",
        "y_reg = np.clip(y_reg, -10, 10)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3) Split data exactly as authors do:\n",
        "#    70% train / 10% validation / 20% test (without shuffling)\n",
        "# --------------------------------------------------\n",
        "X_temp, X_test, y_reg_temp, y_reg_test, y_clf_temp, y_clf_test = train_test_split(\n",
        "    X, y_reg, y_clf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, y_reg_train, y_reg_val, y_clf_train, y_clf_val = train_test_split(\n",
        "    X_temp, y_reg_temp, y_clf_temp, test_size=0.125, shuffle=False)\n",
        "\n",
        "print(\"Shapes → Train:\", X_train.shape, \"Validation:\", X_val.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4) Build the multitask model (exact paper setting)\n",
        "# --------------------------------------------------\n",
        "def build_multitask_model(input_shape):\n",
        "    inp = Input(shape=input_shape)  # Expected input shape: (50, 48)\n",
        "\n",
        "    # Shared layers:\n",
        "    x = LSTM(15, return_sequences=False)(inp)\n",
        "    x = Dense(30, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(30, activation='relu')(x)\n",
        "\n",
        "    # Regression task-specific branch (3 FC layers of 30 neurons each)\n",
        "    reg_branch = Dense(30, activation='relu')(x)\n",
        "    reg_branch = Dense(30, activation='relu')(reg_branch)\n",
        "    reg_branch = Dense(30, activation='relu')(reg_branch)\n",
        "    out_reg = Dense(1, name='regression')(reg_branch)\n",
        "\n",
        "    # Classification task-specific branch (3 FC layers of 30 neurons each)\n",
        "    clf_branch = Dense(30, activation='relu')(x)\n",
        "    clf_branch = Dense(30, activation='relu')(clf_branch)\n",
        "    clf_branch = Dense(30, activation='relu')(clf_branch)\n",
        "    out_clf = Dense(2, activation='softmax', name='classification')(clf_branch)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=[out_reg, out_clf])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss={'regression': 'mse', 'classification': 'sparse_categorical_crossentropy'},\n",
        "                  loss_weights={'regression': 0.1, 'classification': 1.0})\n",
        "    return model\n",
        "\n",
        "model = build_multitask_model((X_train.shape[1], X_train.shape[2]))\n",
        "model.summary()\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5) Define learning rate scheduler and early stopping\n",
        "# --------------------------------------------------\n",
        "def lr_schedule(epoch, lr):\n",
        "    # Halve the learning rate every 50 epochs\n",
        "    return 1e-3 * (0.5 ** (epoch // 50))\n",
        "\n",
        "lr_cb = LearningRateScheduler(lr_schedule)\n",
        "es_cb = EarlyStopping(patience=20, restore_best_weights=True)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 6) Train the model for 300 epochs\n",
        "# --------------------------------------------------\n",
        "history = model.fit(\n",
        "    X_train, {'regression': y_reg_train, 'classification': y_clf_train},\n",
        "    validation_data=(X_val, {'regression': y_reg_val, 'classification': y_clf_val}),\n",
        "    epochs=300,\n",
        "    batch_size=256,\n",
        "    callbacks=[lr_cb, es_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 7) Evaluate the model on the test set\n",
        "# --------------------------------------------------\n",
        "pred_reg, pred_clf = model.predict(X_test, verbose=0)\n",
        "pred_clf = pred_clf.argmax(axis=1)\n",
        "\n",
        "rmse = math.sqrt(mean_squared_error(y_reg_test, pred_reg))\n",
        "acc = accuracy_score(y_clf_test, pred_clf)\n",
        "bacc = balanced_accuracy_score(y_clf_test, pred_clf)\n",
        "\n",
        "print(\"Test RMSE:\", rmse)\n",
        "print(\"Test Accuracy:\", acc)\n",
        "print(\"Test Balanced Accuracy:\", bacc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ih6nfnBuEJZD",
        "outputId": "45efde7c-414b-48bf-fea2-3fb382fb04b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes → Train: (2751, 50, 48) Validation: (393, 50, 48) Test: (786, 50, 48)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │          \u001b[38;5;34m3,840\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m480\u001b[0m │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ regression (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m31\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ classification (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m62\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ regression (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ classification (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,923\u001b[0m (42.67 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,923</span> (42.67 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,923\u001b[0m (42.67 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,923</span> (42.67 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - classification_loss: 0.6910 - loss: 1.7049 - regression_loss: 10.1348 - val_classification_loss: 0.6932 - val_loss: 0.8142 - val_regression_loss: 1.2630 - learning_rate: 0.0010\n",
            "Epoch 2/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6880 - loss: 1.6324 - regression_loss: 9.4481 - val_classification_loss: 0.6920 - val_loss: 0.8128 - val_regression_loss: 1.2572 - learning_rate: 0.0010\n",
            "Epoch 3/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - classification_loss: 0.6861 - loss: 1.6804 - regression_loss: 9.9304 - val_classification_loss: 0.6909 - val_loss: 0.8120 - val_regression_loss: 1.2571 - learning_rate: 0.0010\n",
            "Epoch 4/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6885 - loss: 1.6613 - regression_loss: 9.7289 - val_classification_loss: 0.6907 - val_loss: 0.8119 - val_regression_loss: 1.2568 - learning_rate: 0.0010\n",
            "Epoch 5/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6883 - loss: 1.6570 - regression_loss: 9.6842 - val_classification_loss: 0.6920 - val_loss: 0.8127 - val_regression_loss: 1.2568 - learning_rate: 0.0010\n",
            "Epoch 6/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6867 - loss: 1.6992 - regression_loss: 10.1212 - val_classification_loss: 0.6919 - val_loss: 0.8126 - val_regression_loss: 1.2566 - learning_rate: 0.0010\n",
            "Epoch 7/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6886 - loss: 1.6706 - regression_loss: 9.8193 - val_classification_loss: 0.6915 - val_loss: 0.8124 - val_regression_loss: 1.2564 - learning_rate: 0.0010\n",
            "Epoch 8/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6900 - loss: 1.7036 - regression_loss: 10.1413 - val_classification_loss: 0.6917 - val_loss: 0.8125 - val_regression_loss: 1.2564 - learning_rate: 0.0010\n",
            "Epoch 9/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6881 - loss: 1.6788 - regression_loss: 9.9074 - val_classification_loss: 0.6918 - val_loss: 0.8126 - val_regression_loss: 1.2567 - learning_rate: 0.0010\n",
            "Epoch 10/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - classification_loss: 0.6904 - loss: 1.6428 - regression_loss: 9.5211 - val_classification_loss: 0.6913 - val_loss: 0.8123 - val_regression_loss: 1.2571 - learning_rate: 0.0010\n",
            "Epoch 11/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - classification_loss: 0.6901 - loss: 1.7132 - regression_loss: 10.2269 - val_classification_loss: 0.6917 - val_loss: 0.8125 - val_regression_loss: 1.2569 - learning_rate: 0.0010\n",
            "Epoch 12/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - classification_loss: 0.6868 - loss: 1.7245 - regression_loss: 10.3752 - val_classification_loss: 0.6922 - val_loss: 0.8129 - val_regression_loss: 1.2570 - learning_rate: 0.0010\n",
            "Epoch 13/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - classification_loss: 0.6895 - loss: 1.7279 - regression_loss: 10.3723 - val_classification_loss: 0.6914 - val_loss: 0.8123 - val_regression_loss: 1.2571 - learning_rate: 0.0010\n",
            "Epoch 14/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6879 - loss: 1.7368 - regression_loss: 10.4805 - val_classification_loss: 0.6915 - val_loss: 0.8124 - val_regression_loss: 1.2570 - learning_rate: 0.0010\n",
            "Epoch 15/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6892 - loss: 1.6290 - regression_loss: 9.3992 - val_classification_loss: 0.6922 - val_loss: 0.8129 - val_regression_loss: 1.2571 - learning_rate: 0.0010\n",
            "Epoch 16/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6908 - loss: 1.6819 - regression_loss: 9.9087 - val_classification_loss: 0.6923 - val_loss: 0.8130 - val_regression_loss: 1.2574 - learning_rate: 0.0010\n",
            "Epoch 17/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6890 - loss: 1.7033 - regression_loss: 10.1434 - val_classification_loss: 0.6917 - val_loss: 0.8126 - val_regression_loss: 1.2572 - learning_rate: 0.0010\n",
            "Epoch 18/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6867 - loss: 1.7375 - regression_loss: 10.5060 - val_classification_loss: 0.6918 - val_loss: 0.8127 - val_regression_loss: 1.2573 - learning_rate: 0.0010\n",
            "Epoch 19/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6866 - loss: 1.6661 - regression_loss: 9.7948 - val_classification_loss: 0.6912 - val_loss: 0.8127 - val_regression_loss: 1.2599 - learning_rate: 0.0010\n",
            "Epoch 20/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6884 - loss: 1.6895 - regression_loss: 10.0120 - val_classification_loss: 0.6916 - val_loss: 0.8128 - val_regression_loss: 1.2594 - learning_rate: 0.0010\n",
            "Epoch 21/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6868 - loss: 1.7212 - regression_loss: 10.3423 - val_classification_loss: 0.6914 - val_loss: 0.8130 - val_regression_loss: 1.2639 - learning_rate: 0.0010\n",
            "Epoch 22/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6890 - loss: 1.6781 - regression_loss: 9.8936 - val_classification_loss: 0.6919 - val_loss: 0.8128 - val_regression_loss: 1.2576 - learning_rate: 0.0010\n",
            "Epoch 23/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6887 - loss: 1.6325 - regression_loss: 9.4386 - val_classification_loss: 0.6926 - val_loss: 0.8134 - val_regression_loss: 1.2585 - learning_rate: 0.0010\n",
            "Epoch 24/300\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6892 - loss: 1.6918 - regression_loss: 10.0274 - val_classification_loss: 0.6920 - val_loss: 0.8130 - val_regression_loss: 1.2593 - learning_rate: 0.0010\n",
            "Test RMSE: 1.1982283175395558\n",
            "Test Accuracy: 0.5330788804071247\n",
            "Test Balanced Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, balanced_accuracy_score\n",
        "\n",
        "# ------------------------------\n",
        "# 1) Load preprocessed dataset\n",
        "# ------------------------------\n",
        "data = np.load(\"SP500_preprocessed.npz\")\n",
        "X, y_reg, y_clf = data['X'], data['y_reg'], data['y_clf']\n",
        "\n",
        "# ------------------------------\n",
        "# 2) Clean the data (as in one-task version)\n",
        "# ------------------------------\n",
        "mask = (~np.isnan(y_reg)) & (~np.isinf(y_reg))\n",
        "X, y_reg, y_clf = X[mask], y_reg[mask], y_clf[mask]\n",
        "y_reg = np.clip(y_reg, -10, 10)  # Clip extreme values\n",
        "\n",
        "# ------------------------------\n",
        "# 3) Split data exactly as authors do:\n",
        "#    70% train / 10% validation / 20% test (without shuffling)\n",
        "# ------------------------------\n",
        "X_temp, X_test, y_reg_temp, y_reg_test, y_clf_temp, y_clf_test = train_test_split(\n",
        "    X, y_reg, y_clf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, y_reg_train, y_reg_val, y_clf_train, y_clf_val = train_test_split(\n",
        "    X_temp, y_reg_temp, y_clf_temp, test_size=0.125, shuffle=False)\n",
        "\n",
        "print(\"Shapes → Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# ------------------------------\n",
        "# 4) Build the multitask model (same architecture as before)\n",
        "# ------------------------------\n",
        "def build_multitask_model():\n",
        "    inp = Input(shape=(50, X.shape[2]))  # Expected input shape: (50, 48) if you have 48 features\n",
        "    x = LSTM(15, return_sequences=False)(inp)\n",
        "    x = Dense(30, activation='relu')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(30, activation='relu')(x)\n",
        "\n",
        "    # Regression branch: 3 FC layers\n",
        "    reg_branch = Dense(30, activation='relu')(x)\n",
        "    reg_branch = Dense(30, activation='relu')(reg_branch)\n",
        "    reg_branch = Dense(30, activation='relu')(reg_branch)\n",
        "    out_reg = Dense(1, name='regression')(reg_branch)\n",
        "\n",
        "    # Classification branch: 3 FC layers\n",
        "    clf_branch = Dense(30, activation='relu')(x)\n",
        "    clf_branch = Dense(30, activation='relu')(clf_branch)\n",
        "    clf_branch = Dense(30, activation='relu')(clf_branch)\n",
        "    out_clf = Dense(2, activation='softmax', name='classification')(clf_branch)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=[out_reg, out_clf])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss={'regression': 'mse', 'classification': 'sparse_categorical_crossentropy'},\n",
        "                  loss_weights={'regression': 0.1, 'classification': 1.0})\n",
        "    return model\n",
        "\n",
        "model = build_multitask_model()\n",
        "model.summary()\n",
        "\n",
        "# Verify no NaNs in training data\n",
        "print(\"Train X NaNs:\", np.isnan(X_train).sum(), \"y_reg NaNs:\", np.isnan(y_reg_train).sum())\n",
        "\n",
        "# ------------------------------\n",
        "# 5) Set up learning rate scheduler and early stopping\n",
        "# ------------------------------\n",
        "def lr_schedule(epoch, lr):\n",
        "    # Halve the learning rate every 50 epochs\n",
        "    return 1e-3 * (0.5 ** (epoch // 50))\n",
        "\n",
        "lr_cb = LearningRateScheduler(lr_schedule)\n",
        "# Increase patience to 50 epochs for a longer training period\n",
        "es_cb = EarlyStopping(patience=50, restore_best_weights=True)\n",
        "\n",
        "# ------------------------------\n",
        "# 6) Train the model for up to 500 epochs\n",
        "# ------------------------------\n",
        "history = model.fit(\n",
        "    X_train, {'regression': y_reg_train, 'classification': y_clf_train},\n",
        "    validation_data=(X_val, {'regression': y_reg_val, 'classification': y_clf_val}),\n",
        "    epochs=500,\n",
        "    batch_size=256,\n",
        "    callbacks=[lr_cb, es_cb],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 7) Evaluate the model on the test set\n",
        "# ------------------------------\n",
        "pred_reg, pred_clf = model.predict(X_test, verbose=0)\n",
        "pred_clf = pred_clf.argmax(axis=1)\n",
        "\n",
        "rmse = math.sqrt(mean_squared_error(y_reg_test, pred_reg))\n",
        "acc = accuracy_score(y_clf_test, pred_clf)\n",
        "bacc = balanced_accuracy_score(y_clf_test, pred_clf)\n",
        "\n",
        "print(\"Test RMSE:\", rmse)\n",
        "print(\"Test Accuracy:\", acc)\n",
        "print(\"Test Balanced Accuracy:\", bacc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fDGHFeY0J8Yj",
        "outputId": "0c6376c3-03bb-4580-b6de-c61914dcc9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes → Train: (2751, 50, 48) Val: (393, 50, 48) Test: (786, 50, 48)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m48\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │          \u001b[38;5;34m3,840\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m480\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │            \u001b[38;5;34m930\u001b[0m │ dense_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ regression (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m31\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ classification (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m62\u001b[0m │ dense_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">3,840</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ regression (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ classification (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span> │ dense_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,923\u001b[0m (42.67 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,923</span> (42.67 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,923\u001b[0m (42.67 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,923</span> (42.67 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train X NaNs: 0 y_reg NaNs: 0\n",
            "Epoch 1/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 87ms/step - classification_loss: 0.6926 - loss: 1.6778 - regression_loss: 9.8530 - val_classification_loss: 0.6911 - val_loss: 0.8130 - val_regression_loss: 1.2604 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6892 - loss: 1.6927 - regression_loss: 10.0295 - val_classification_loss: 0.6923 - val_loss: 0.8136 - val_regression_loss: 1.2609 - learning_rate: 0.0010\n",
            "Epoch 3/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6878 - loss: 1.6393 - regression_loss: 9.5107 - val_classification_loss: 0.6924 - val_loss: 0.8136 - val_regression_loss: 1.2606 - learning_rate: 0.0010\n",
            "Epoch 4/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - classification_loss: 0.6887 - loss: 1.6775 - regression_loss: 9.8884 - val_classification_loss: 0.6915 - val_loss: 0.8129 - val_regression_loss: 1.2597 - learning_rate: 0.0010\n",
            "Epoch 5/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - classification_loss: 0.6912 - loss: 1.6811 - regression_loss: 9.8980 - val_classification_loss: 0.6912 - val_loss: 0.8127 - val_regression_loss: 1.2600 - learning_rate: 0.0010\n",
            "Epoch 6/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - classification_loss: 0.6870 - loss: 1.6950 - regression_loss: 10.0769 - val_classification_loss: 0.6915 - val_loss: 0.8129 - val_regression_loss: 1.2604 - learning_rate: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6881 - loss: 1.6500 - regression_loss: 9.6255 - val_classification_loss: 0.6912 - val_loss: 0.8126 - val_regression_loss: 1.2597 - learning_rate: 0.0010\n",
            "Epoch 8/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6852 - loss: 1.6761 - regression_loss: 9.9073 - val_classification_loss: 0.6912 - val_loss: 0.8126 - val_regression_loss: 1.2600 - learning_rate: 0.0010\n",
            "Epoch 9/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6876 - loss: 1.7271 - regression_loss: 10.4007 - val_classification_loss: 0.6909 - val_loss: 0.8131 - val_regression_loss: 1.2657 - learning_rate: 0.0010\n",
            "Epoch 10/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6901 - loss: 1.6402 - regression_loss: 9.5005 - val_classification_loss: 0.6909 - val_loss: 0.8132 - val_regression_loss: 1.2662 - learning_rate: 0.0010\n",
            "Epoch 11/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6877 - loss: 1.6593 - regression_loss: 9.7116 - val_classification_loss: 0.6913 - val_loss: 0.8130 - val_regression_loss: 1.2631 - learning_rate: 0.0010\n",
            "Epoch 12/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6886 - loss: 1.7261 - regression_loss: 10.3723 - val_classification_loss: 0.6913 - val_loss: 0.8134 - val_regression_loss: 1.2661 - learning_rate: 0.0010\n",
            "Epoch 13/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6889 - loss: 1.7175 - regression_loss: 10.2901 - val_classification_loss: 0.6911 - val_loss: 0.8138 - val_regression_loss: 1.2717 - learning_rate: 0.0010\n",
            "Epoch 14/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6890 - loss: 1.6284 - regression_loss: 9.3992 - val_classification_loss: 0.6913 - val_loss: 0.8134 - val_regression_loss: 1.2675 - learning_rate: 0.0010\n",
            "Epoch 15/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6880 - loss: 1.6881 - regression_loss: 9.9923 - val_classification_loss: 0.6912 - val_loss: 0.8136 - val_regression_loss: 1.2698 - learning_rate: 0.0010\n",
            "Epoch 16/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6876 - loss: 1.6614 - regression_loss: 9.7357 - val_classification_loss: 0.6913 - val_loss: 0.8147 - val_regression_loss: 1.2791 - learning_rate: 0.0010\n",
            "Epoch 17/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6919 - loss: 1.6537 - regression_loss: 9.6180 - val_classification_loss: 0.6909 - val_loss: 0.8149 - val_regression_loss: 1.2823 - learning_rate: 0.0010\n",
            "Epoch 18/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - classification_loss: 0.6892 - loss: 1.6981 - regression_loss: 10.0846 - val_classification_loss: 0.6914 - val_loss: 0.8125 - val_regression_loss: 1.2581 - learning_rate: 0.0010\n",
            "Epoch 19/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - classification_loss: 0.6903 - loss: 1.6602 - regression_loss: 9.6969 - val_classification_loss: 0.6912 - val_loss: 0.8126 - val_regression_loss: 1.2594 - learning_rate: 0.0010\n",
            "Epoch 20/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6889 - loss: 1.6922 - regression_loss: 10.0256 - val_classification_loss: 0.6913 - val_loss: 0.8133 - val_regression_loss: 1.2649 - learning_rate: 0.0010\n",
            "Epoch 21/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - classification_loss: 0.6882 - loss: 1.6860 - regression_loss: 9.9742 - val_classification_loss: 0.6911 - val_loss: 0.8133 - val_regression_loss: 1.2663 - learning_rate: 0.0010\n",
            "Epoch 22/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - classification_loss: 0.6885 - loss: 1.6652 - regression_loss: 9.7549 - val_classification_loss: 0.6910 - val_loss: 0.8133 - val_regression_loss: 1.2669 - learning_rate: 0.0010\n",
            "Epoch 23/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6856 - loss: 1.6398 - regression_loss: 9.5438 - val_classification_loss: 0.6913 - val_loss: 0.8128 - val_regression_loss: 1.2619 - learning_rate: 0.0010\n",
            "Epoch 24/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6878 - loss: 1.6548 - regression_loss: 9.6746 - val_classification_loss: 0.6912 - val_loss: 0.8143 - val_regression_loss: 1.2760 - learning_rate: 0.0010\n",
            "Epoch 25/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - classification_loss: 0.6886 - loss: 1.6414 - regression_loss: 9.5355 - val_classification_loss: 0.6915 - val_loss: 0.8130 - val_regression_loss: 1.2619 - learning_rate: 0.0010\n",
            "Epoch 26/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - classification_loss: 0.6897 - loss: 1.6038 - regression_loss: 9.1399 - val_classification_loss: 0.6914 - val_loss: 0.8126 - val_regression_loss: 1.2585 - learning_rate: 0.0010\n",
            "Epoch 27/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - classification_loss: 0.6846 - loss: 1.6132 - regression_loss: 9.2895 - val_classification_loss: 0.6910 - val_loss: 0.8155 - val_regression_loss: 1.2903 - learning_rate: 0.0010\n",
            "Epoch 28/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6881 - loss: 1.6560 - regression_loss: 9.6742 - val_classification_loss: 0.6911 - val_loss: 0.8148 - val_regression_loss: 1.2817 - learning_rate: 0.0010\n",
            "Epoch 29/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6875 - loss: 1.6599 - regression_loss: 9.7266 - val_classification_loss: 0.6912 - val_loss: 0.8130 - val_regression_loss: 1.2642 - learning_rate: 0.0010\n",
            "Epoch 30/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6892 - loss: 1.6855 - regression_loss: 9.9536 - val_classification_loss: 0.6911 - val_loss: 0.8139 - val_regression_loss: 1.2737 - learning_rate: 0.0010\n",
            "Epoch 31/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6892 - loss: 1.6940 - regression_loss: 10.0523 - val_classification_loss: 0.6911 - val_loss: 0.8131 - val_regression_loss: 1.2666 - learning_rate: 0.0010\n",
            "Epoch 32/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6882 - loss: 1.6906 - regression_loss: 10.0151 - val_classification_loss: 0.6912 - val_loss: 0.8141 - val_regression_loss: 1.2768 - learning_rate: 0.0010\n",
            "Epoch 33/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6881 - loss: 1.6876 - regression_loss: 9.9889 - val_classification_loss: 0.6912 - val_loss: 0.8135 - val_regression_loss: 1.2704 - learning_rate: 0.0010\n",
            "Epoch 34/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6883 - loss: 1.7074 - regression_loss: 10.1920 - val_classification_loss: 0.6910 - val_loss: 0.8144 - val_regression_loss: 1.2822 - learning_rate: 0.0010\n",
            "Epoch 35/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6897 - loss: 1.6754 - regression_loss: 9.8565 - val_classification_loss: 0.6912 - val_loss: 0.8132 - val_regression_loss: 1.2686 - learning_rate: 0.0010\n",
            "Epoch 36/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6879 - loss: 1.6795 - regression_loss: 9.9160 - val_classification_loss: 0.6912 - val_loss: 0.8134 - val_regression_loss: 1.2712 - learning_rate: 0.0010\n",
            "Epoch 37/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6889 - loss: 1.6624 - regression_loss: 9.7420 - val_classification_loss: 0.6914 - val_loss: 0.8138 - val_regression_loss: 1.2735 - learning_rate: 0.0010\n",
            "Epoch 38/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6865 - loss: 1.6379 - regression_loss: 9.5224 - val_classification_loss: 0.6914 - val_loss: 0.8134 - val_regression_loss: 1.2692 - learning_rate: 0.0010\n",
            "Epoch 39/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6862 - loss: 1.7052 - regression_loss: 10.1971 - val_classification_loss: 0.6914 - val_loss: 0.8144 - val_regression_loss: 1.2795 - learning_rate: 0.0010\n",
            "Epoch 40/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6895 - loss: 1.6104 - regression_loss: 9.2178 - val_classification_loss: 0.6914 - val_loss: 0.8124 - val_regression_loss: 1.2576 - learning_rate: 0.0010\n",
            "Epoch 41/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6890 - loss: 1.7214 - regression_loss: 10.3311 - val_classification_loss: 0.6919 - val_loss: 0.8126 - val_regression_loss: 1.2560 - learning_rate: 0.0010\n",
            "Epoch 42/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6872 - loss: 1.7270 - regression_loss: 10.4040 - val_classification_loss: 0.6914 - val_loss: 0.8128 - val_regression_loss: 1.2622 - learning_rate: 0.0010\n",
            "Epoch 43/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6891 - loss: 1.6221 - regression_loss: 9.3301 - val_classification_loss: 0.6912 - val_loss: 0.8125 - val_regression_loss: 1.2601 - learning_rate: 0.0010\n",
            "Epoch 44/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6881 - loss: 1.6935 - regression_loss: 10.0616 - val_classification_loss: 0.6923 - val_loss: 0.8135 - val_regression_loss: 1.2620 - learning_rate: 0.0010\n",
            "Epoch 45/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - classification_loss: 0.6866 - loss: 1.6481 - regression_loss: 9.6100 - val_classification_loss: 0.6925 - val_loss: 0.8178 - val_regression_loss: 1.3029 - learning_rate: 0.0010\n",
            "Epoch 46/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - classification_loss: 0.6858 - loss: 1.6617 - regression_loss: 9.7540 - val_classification_loss: 0.6934 - val_loss: 0.8142 - val_regression_loss: 1.2603 - learning_rate: 0.0010\n",
            "Epoch 47/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - classification_loss: 0.6850 - loss: 1.6638 - regression_loss: 9.7784 - val_classification_loss: 0.6916 - val_loss: 0.8133 - val_regression_loss: 1.2654 - learning_rate: 0.0010\n",
            "Epoch 48/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6833 - loss: 1.6475 - regression_loss: 9.6509 - val_classification_loss: 0.6916 - val_loss: 0.8130 - val_regression_loss: 1.2632 - learning_rate: 0.0010\n",
            "Epoch 49/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6886 - loss: 1.6645 - regression_loss: 9.7519 - val_classification_loss: 0.6913 - val_loss: 0.8126 - val_regression_loss: 1.2594 - learning_rate: 0.0010\n",
            "Epoch 50/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6875 - loss: 1.6079 - regression_loss: 9.2085 - val_classification_loss: 0.6926 - val_loss: 0.8134 - val_regression_loss: 1.2588 - learning_rate: 0.0010\n",
            "Epoch 51/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6868 - loss: 1.6932 - regression_loss: 10.0602 - val_classification_loss: 0.6925 - val_loss: 0.8132 - val_regression_loss: 1.2584 - learning_rate: 5.0000e-04\n",
            "Epoch 52/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6883 - loss: 1.7079 - regression_loss: 10.1950 - val_classification_loss: 0.6919 - val_loss: 0.8125 - val_regression_loss: 1.2559 - learning_rate: 5.0000e-04\n",
            "Epoch 53/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6842 - loss: 1.6401 - regression_loss: 9.5574 - val_classification_loss: 0.6919 - val_loss: 0.8130 - val_regression_loss: 1.2593 - learning_rate: 5.0000e-04\n",
            "Epoch 54/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6865 - loss: 1.6616 - regression_loss: 9.7538 - val_classification_loss: 0.6920 - val_loss: 0.8128 - val_regression_loss: 1.2575 - learning_rate: 5.0000e-04\n",
            "Epoch 55/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6886 - loss: 1.6589 - regression_loss: 9.7008 - val_classification_loss: 0.6918 - val_loss: 0.8127 - val_regression_loss: 1.2576 - learning_rate: 5.0000e-04\n",
            "Epoch 56/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6857 - loss: 1.6535 - regression_loss: 9.6774 - val_classification_loss: 0.6923 - val_loss: 0.8130 - val_regression_loss: 1.2577 - learning_rate: 5.0000e-04\n",
            "Epoch 57/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6879 - loss: 1.6740 - regression_loss: 9.8562 - val_classification_loss: 0.6927 - val_loss: 0.8132 - val_regression_loss: 1.2567 - learning_rate: 5.0000e-04\n",
            "Epoch 58/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6881 - loss: 1.7122 - regression_loss: 10.2326 - val_classification_loss: 0.6926 - val_loss: 0.8131 - val_regression_loss: 1.2564 - learning_rate: 5.0000e-04\n",
            "Epoch 59/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6886 - loss: 1.6584 - regression_loss: 9.6968 - val_classification_loss: 0.6932 - val_loss: 0.8135 - val_regression_loss: 1.2561 - learning_rate: 5.0000e-04\n",
            "Epoch 60/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6869 - loss: 1.6979 - regression_loss: 10.1124 - val_classification_loss: 0.6932 - val_loss: 0.8135 - val_regression_loss: 1.2554 - learning_rate: 5.0000e-04\n",
            "Epoch 61/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6831 - loss: 1.6394 - regression_loss: 9.5634 - val_classification_loss: 0.6922 - val_loss: 0.8128 - val_regression_loss: 1.2562 - learning_rate: 5.0000e-04\n",
            "Epoch 62/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6876 - loss: 1.7047 - regression_loss: 10.1650 - val_classification_loss: 0.6916 - val_loss: 0.8121 - val_regression_loss: 1.2546 - learning_rate: 5.0000e-04\n",
            "Epoch 63/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6873 - loss: 1.6698 - regression_loss: 9.8288 - val_classification_loss: 0.6914 - val_loss: 0.8122 - val_regression_loss: 1.2564 - learning_rate: 5.0000e-04\n",
            "Epoch 64/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6876 - loss: 1.7002 - regression_loss: 10.1171 - val_classification_loss: 0.6916 - val_loss: 0.8125 - val_regression_loss: 1.2577 - learning_rate: 5.0000e-04\n",
            "Epoch 65/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6873 - loss: 1.6293 - regression_loss: 9.4180 - val_classification_loss: 0.6921 - val_loss: 0.8126 - val_regression_loss: 1.2559 - learning_rate: 5.0000e-04\n",
            "Epoch 66/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - classification_loss: 0.6854 - loss: 1.6400 - regression_loss: 9.5465 - val_classification_loss: 0.6921 - val_loss: 0.8125 - val_regression_loss: 1.2550 - learning_rate: 5.0000e-04\n",
            "Epoch 67/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - classification_loss: 0.6848 - loss: 1.6459 - regression_loss: 9.6069 - val_classification_loss: 0.6917 - val_loss: 0.8124 - val_regression_loss: 1.2559 - learning_rate: 5.0000e-04\n",
            "Epoch 68/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - classification_loss: 0.6844 - loss: 1.6609 - regression_loss: 9.7613 - val_classification_loss: 0.6916 - val_loss: 0.8121 - val_regression_loss: 1.2550 - learning_rate: 5.0000e-04\n",
            "Epoch 69/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6851 - loss: 1.5845 - regression_loss: 9.0063 - val_classification_loss: 0.6914 - val_loss: 0.8123 - val_regression_loss: 1.2581 - learning_rate: 5.0000e-04\n",
            "Epoch 70/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6888 - loss: 1.6350 - regression_loss: 9.4543 - val_classification_loss: 0.6914 - val_loss: 0.8124 - val_regression_loss: 1.2580 - learning_rate: 5.0000e-04\n",
            "Epoch 71/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6884 - loss: 1.6921 - regression_loss: 10.0396 - val_classification_loss: 0.6918 - val_loss: 0.8122 - val_regression_loss: 1.2540 - learning_rate: 5.0000e-04\n",
            "Epoch 72/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6861 - loss: 1.6425 - regression_loss: 9.5618 - val_classification_loss: 0.6917 - val_loss: 0.8124 - val_regression_loss: 1.2568 - learning_rate: 5.0000e-04\n",
            "Epoch 73/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6881 - loss: 1.6920 - regression_loss: 10.0494 - val_classification_loss: 0.6915 - val_loss: 0.8122 - val_regression_loss: 1.2556 - learning_rate: 5.0000e-04\n",
            "Epoch 74/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - classification_loss: 0.6837 - loss: 1.6409 - regression_loss: 9.5704 - val_classification_loss: 0.6910 - val_loss: 0.8114 - val_regression_loss: 1.2525 - learning_rate: 5.0000e-04\n",
            "Epoch 75/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6852 - loss: 1.6737 - regression_loss: 9.8714 - val_classification_loss: 0.6906 - val_loss: 0.8120 - val_regression_loss: 1.2602 - learning_rate: 5.0000e-04\n",
            "Epoch 76/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6819 - loss: 1.6103 - regression_loss: 9.2899 - val_classification_loss: 0.6912 - val_loss: 0.8118 - val_regression_loss: 1.2549 - learning_rate: 5.0000e-04\n",
            "Epoch 77/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6849 - loss: 1.6347 - regression_loss: 9.4968 - val_classification_loss: 0.6914 - val_loss: 0.8120 - val_regression_loss: 1.2547 - learning_rate: 5.0000e-04\n",
            "Epoch 78/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - classification_loss: 0.6844 - loss: 1.6401 - regression_loss: 9.5566 - val_classification_loss: 0.6913 - val_loss: 0.8121 - val_regression_loss: 1.2568 - learning_rate: 5.0000e-04\n",
            "Epoch 79/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6857 - loss: 1.5774 - regression_loss: 8.9173 - val_classification_loss: 0.6912 - val_loss: 0.8118 - val_regression_loss: 1.2540 - learning_rate: 5.0000e-04\n",
            "Epoch 80/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6877 - loss: 1.6550 - regression_loss: 9.6799 - val_classification_loss: 0.6912 - val_loss: 0.8117 - val_regression_loss: 1.2545 - learning_rate: 5.0000e-04\n",
            "Epoch 81/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6869 - loss: 1.6416 - regression_loss: 9.5427 - val_classification_loss: 0.6909 - val_loss: 0.8124 - val_regression_loss: 1.2614 - learning_rate: 5.0000e-04\n",
            "Epoch 82/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6866 - loss: 1.6575 - regression_loss: 9.7109 - val_classification_loss: 0.6910 - val_loss: 0.8121 - val_regression_loss: 1.2581 - learning_rate: 5.0000e-04\n",
            "Epoch 83/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6865 - loss: 1.6737 - regression_loss: 9.8729 - val_classification_loss: 0.6910 - val_loss: 0.8120 - val_regression_loss: 1.2577 - learning_rate: 5.0000e-04\n",
            "Epoch 84/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6815 - loss: 1.5816 - regression_loss: 9.0112 - val_classification_loss: 0.6912 - val_loss: 0.8121 - val_regression_loss: 1.2565 - learning_rate: 5.0000e-04\n",
            "Epoch 85/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - classification_loss: 0.6863 - loss: 1.5668 - regression_loss: 8.8124 - val_classification_loss: 0.6910 - val_loss: 0.8116 - val_regression_loss: 1.2540 - learning_rate: 5.0000e-04\n",
            "Epoch 86/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - classification_loss: 0.6824 - loss: 1.6351 - regression_loss: 9.5284 - val_classification_loss: 0.6912 - val_loss: 0.8118 - val_regression_loss: 1.2541 - learning_rate: 5.0000e-04\n",
            "Epoch 87/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - classification_loss: 0.6857 - loss: 1.6294 - regression_loss: 9.4402 - val_classification_loss: 0.6911 - val_loss: 0.8127 - val_regression_loss: 1.2626 - learning_rate: 5.0000e-04\n",
            "Epoch 88/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - classification_loss: 0.6845 - loss: 1.6904 - regression_loss: 10.0532 - val_classification_loss: 0.6919 - val_loss: 0.8123 - val_regression_loss: 1.2540 - learning_rate: 5.0000e-04\n",
            "Epoch 89/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6878 - loss: 1.6025 - regression_loss: 9.1420 - val_classification_loss: 0.6916 - val_loss: 0.8122 - val_regression_loss: 1.2548 - learning_rate: 5.0000e-04\n",
            "Epoch 90/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6850 - loss: 1.6788 - regression_loss: 9.9350 - val_classification_loss: 0.6916 - val_loss: 0.8122 - val_regression_loss: 1.2548 - learning_rate: 5.0000e-04\n",
            "Epoch 91/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6835 - loss: 1.6070 - regression_loss: 9.2288 - val_classification_loss: 0.6923 - val_loss: 0.8127 - val_regression_loss: 1.2548 - learning_rate: 5.0000e-04\n",
            "Epoch 92/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6898 - loss: 1.6676 - regression_loss: 9.7733 - val_classification_loss: 0.6913 - val_loss: 0.8118 - val_regression_loss: 1.2532 - learning_rate: 5.0000e-04\n",
            "Epoch 93/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6837 - loss: 1.6270 - regression_loss: 9.4290 - val_classification_loss: 0.6911 - val_loss: 0.8118 - val_regression_loss: 1.2561 - learning_rate: 5.0000e-04\n",
            "Epoch 94/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6846 - loss: 1.6518 - regression_loss: 9.6672 - val_classification_loss: 0.6911 - val_loss: 0.8120 - val_regression_loss: 1.2571 - learning_rate: 5.0000e-04\n",
            "Epoch 95/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6865 - loss: 1.6818 - regression_loss: 9.9525 - val_classification_loss: 0.6911 - val_loss: 0.8119 - val_regression_loss: 1.2556 - learning_rate: 5.0000e-04\n",
            "Epoch 96/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6803 - loss: 1.6108 - regression_loss: 9.3057 - val_classification_loss: 0.6915 - val_loss: 0.8122 - val_regression_loss: 1.2555 - learning_rate: 5.0000e-04\n",
            "Epoch 97/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6893 - loss: 1.6855 - regression_loss: 9.9625 - val_classification_loss: 0.6912 - val_loss: 0.8120 - val_regression_loss: 1.2560 - learning_rate: 5.0000e-04\n",
            "Epoch 98/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6863 - loss: 1.6597 - regression_loss: 9.7255 - val_classification_loss: 0.6917 - val_loss: 0.8123 - val_regression_loss: 1.2556 - learning_rate: 5.0000e-04\n",
            "Epoch 99/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6862 - loss: 1.6471 - regression_loss: 9.6109 - val_classification_loss: 0.6922 - val_loss: 0.8124 - val_regression_loss: 1.2533 - learning_rate: 5.0000e-04\n",
            "Epoch 100/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6853 - loss: 1.6313 - regression_loss: 9.4637 - val_classification_loss: 0.6924 - val_loss: 0.8127 - val_regression_loss: 1.2538 - learning_rate: 5.0000e-04\n",
            "Epoch 101/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6854 - loss: 1.6432 - regression_loss: 9.5582 - val_classification_loss: 0.6925 - val_loss: 0.8127 - val_regression_loss: 1.2532 - learning_rate: 2.5000e-04\n",
            "Epoch 102/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - classification_loss: 0.6838 - loss: 1.6536 - regression_loss: 9.6897 - val_classification_loss: 0.6922 - val_loss: 0.8124 - val_regression_loss: 1.2535 - learning_rate: 2.5000e-04\n",
            "Epoch 103/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - classification_loss: 0.6800 - loss: 1.5814 - regression_loss: 9.0163 - val_classification_loss: 0.6923 - val_loss: 0.8125 - val_regression_loss: 1.2533 - learning_rate: 2.5000e-04\n",
            "Epoch 104/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - classification_loss: 0.6816 - loss: 1.5996 - regression_loss: 9.1789 - val_classification_loss: 0.6920 - val_loss: 0.8124 - val_regression_loss: 1.2540 - learning_rate: 2.5000e-04\n",
            "Epoch 105/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6859 - loss: 1.5671 - regression_loss: 8.8095 - val_classification_loss: 0.6919 - val_loss: 0.8123 - val_regression_loss: 1.2542 - learning_rate: 2.5000e-04\n",
            "Epoch 106/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step - classification_loss: 0.6805 - loss: 1.6284 - regression_loss: 9.4732 - val_classification_loss: 0.6924 - val_loss: 0.8125 - val_regression_loss: 1.2530 - learning_rate: 2.5000e-04\n",
            "Epoch 107/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - classification_loss: 0.6853 - loss: 1.6154 - regression_loss: 9.2970 - val_classification_loss: 0.6919 - val_loss: 0.8123 - val_regression_loss: 1.2544 - learning_rate: 2.5000e-04\n",
            "Epoch 108/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6853 - loss: 1.5673 - regression_loss: 8.8208 - val_classification_loss: 0.6920 - val_loss: 0.8125 - val_regression_loss: 1.2549 - learning_rate: 2.5000e-04\n",
            "Epoch 109/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6838 - loss: 1.6010 - regression_loss: 9.1780 - val_classification_loss: 0.6922 - val_loss: 0.8125 - val_regression_loss: 1.2538 - learning_rate: 2.5000e-04\n",
            "Epoch 110/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6850 - loss: 1.5946 - regression_loss: 9.0948 - val_classification_loss: 0.6922 - val_loss: 0.8124 - val_regression_loss: 1.2538 - learning_rate: 2.5000e-04\n",
            "Epoch 111/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6842 - loss: 1.6240 - regression_loss: 9.3983 - val_classification_loss: 0.6922 - val_loss: 0.8125 - val_regression_loss: 1.2541 - learning_rate: 2.5000e-04\n",
            "Epoch 112/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - classification_loss: 0.6805 - loss: 1.6294 - regression_loss: 9.4858 - val_classification_loss: 0.6924 - val_loss: 0.8127 - val_regression_loss: 1.2547 - learning_rate: 2.5000e-04\n",
            "Epoch 113/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6857 - loss: 1.6186 - regression_loss: 9.3168 - val_classification_loss: 0.6921 - val_loss: 0.8125 - val_regression_loss: 1.2550 - learning_rate: 2.5000e-04\n",
            "Epoch 114/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6814 - loss: 1.5343 - regression_loss: 8.5293 - val_classification_loss: 0.6926 - val_loss: 0.8129 - val_regression_loss: 1.2547 - learning_rate: 2.5000e-04\n",
            "Epoch 115/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - classification_loss: 0.6850 - loss: 1.6523 - regression_loss: 9.6648 - val_classification_loss: 0.6923 - val_loss: 0.8127 - val_regression_loss: 1.2552 - learning_rate: 2.5000e-04\n",
            "Epoch 116/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - classification_loss: 0.6825 - loss: 1.5862 - regression_loss: 9.0409 - val_classification_loss: 0.6926 - val_loss: 0.8129 - val_regression_loss: 1.2554 - learning_rate: 2.5000e-04\n",
            "Epoch 117/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6833 - loss: 1.6326 - regression_loss: 9.4921 - val_classification_loss: 0.6925 - val_loss: 0.8131 - val_regression_loss: 1.2572 - learning_rate: 2.5000e-04\n",
            "Epoch 118/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6851 - loss: 1.5986 - regression_loss: 9.1387 - val_classification_loss: 0.6925 - val_loss: 0.8130 - val_regression_loss: 1.2567 - learning_rate: 2.5000e-04\n",
            "Epoch 119/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - classification_loss: 0.6819 - loss: 1.6057 - regression_loss: 9.2366 - val_classification_loss: 0.6926 - val_loss: 0.8130 - val_regression_loss: 1.2560 - learning_rate: 2.5000e-04\n",
            "Epoch 120/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - classification_loss: 0.6820 - loss: 1.6398 - regression_loss: 9.5782 - val_classification_loss: 0.6928 - val_loss: 0.8132 - val_regression_loss: 1.2563 - learning_rate: 2.5000e-04\n",
            "Epoch 121/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - classification_loss: 0.6801 - loss: 1.6343 - regression_loss: 9.5472 - val_classification_loss: 0.6929 - val_loss: 0.8134 - val_regression_loss: 1.2565 - learning_rate: 2.5000e-04\n",
            "Epoch 122/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6858 - loss: 1.6137 - regression_loss: 9.2845 - val_classification_loss: 0.6924 - val_loss: 0.8129 - val_regression_loss: 1.2559 - learning_rate: 2.5000e-04\n",
            "Epoch 123/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - classification_loss: 0.6833 - loss: 1.6017 - regression_loss: 9.1722 - val_classification_loss: 0.6924 - val_loss: 0.8129 - val_regression_loss: 1.2556 - learning_rate: 2.5000e-04\n",
            "Epoch 124/500\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - classification_loss: 0.6817 - loss: 1.5978 - regression_loss: 9.1565 - val_classification_loss: 0.6926 - val_loss: 0.8130 - val_regression_loss: 1.2556 - learning_rate: 2.5000e-04\n",
            "Test RMSE: 1.197887563953597\n",
            "Test Accuracy: 0.5330788804071247\n",
            "Test Balanced Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ------------------------------\n",
        "# 1) Load preprocessed dataset (48 features per timestep)\n",
        "# ------------------------------\n",
        "data = np.load(\"SP500_preprocessed.npz\")\n",
        "X, y_reg, y_clf = data['X'], data['y_reg'], data['y_clf']\n",
        "\n",
        "# ------------------------------\n",
        "# 2) Data cleaning (same as one-task)\n",
        "# ------------------------------\n",
        "mask = (~np.isnan(y_reg)) & (~np.isinf(y_reg))\n",
        "X, y_reg, y_clf = X[mask], y_reg[mask], y_clf[mask]\n",
        "y_reg = np.clip(y_reg, -10, 10)  # clip extreme targets\n",
        "\n",
        "# ------------------------------\n",
        "# 3) Split data exactly as authors do:\n",
        "#     70% train / 10% validation / 20% test (without shuffling)\n",
        "# ------------------------------\n",
        "X_temp, X_test, y_reg_temp, y_reg_test, y_clf_temp, y_clf_test = train_test_split(\n",
        "    X, y_reg, y_clf, test_size=0.2, shuffle=False)\n",
        "X_train, X_val, y_reg_train, y_reg_val, y_clf_train, y_clf_val = train_test_split(\n",
        "    X_temp, y_reg_temp, y_clf_temp, test_size=0.125, shuffle=False)\n",
        "\n",
        "print(\"Shapes → Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
        "\n",
        "# ------------------------------\n",
        "# 4) Model building function (as per original paper)\n",
        "# ------------------------------\n",
        "def build_model(input_dim):\n",
        "    inp = Input(shape=(50, input_dim))\n",
        "    x = LSTM(15, return_sequences=False)(inp)\n",
        "    x = Dense(30, activation=\"relu\")(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    x = Dense(30, activation=\"relu\")(x)\n",
        "    # Regression branch (3 Dense layers)\n",
        "    reg_branch = Dense(30, activation=\"relu\")(x)\n",
        "    reg_branch = Dense(30, activation=\"relu\")(reg_branch)\n",
        "    reg_branch = Dense(30, activation=\"relu\")(reg_branch)\n",
        "    out_reg = Dense(1, name=\"regression\")(reg_branch)\n",
        "    # Classification branch (3 Dense layers)\n",
        "    clf_branch = Dense(30, activation=\"relu\")(x)\n",
        "    clf_branch = Dense(30, activation=\"relu\")(clf_branch)\n",
        "    clf_branch = Dense(30, activation=\"relu\")(clf_branch)\n",
        "    out_clf = Dense(2, activation=\"softmax\", name=\"classification\")(clf_branch)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=[out_reg, out_clf])\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "                  loss={\"regression\": \"mse\", \"classification\": \"sparse_categorical_crossentropy\"},\n",
        "                  loss_weights={\"regression\": 0.1, \"classification\": 1.0})\n",
        "    return model\n",
        "\n",
        "# ------------------------------\n",
        "# 5) Learning rate scheduler and early stopping\n",
        "# ------------------------------\n",
        "def lr_schedule(epoch, lr):\n",
        "    # Halve the learning rate every 50 epochs\n",
        "    return 1e-3 * (0.5 ** (epoch // 50))\n",
        "lr_cb = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# ------------------------------\n",
        "# 6) Ensemble training settings\n",
        "# ------------------------------\n",
        "num_models = 100   # Number of ensemble models\n",
        "feature_subset = 13  # Number of features to sample for each model\n",
        "\n",
        "ensemble_preds_reg = []\n",
        "ensemble_preds_clf = []\n",
        "\n",
        "for i in range(num_models):\n",
        "    print(f\"Training model {i+1}/{num_models}\")\n",
        "    # Randomly sample feature indices from 0 to X_train.shape[2]-1\n",
        "    feature_idx = sorted(random.sample(range(X_train.shape[2]), feature_subset))\n",
        "\n",
        "    # Select features from training, validation, and test sets\n",
        "    X_train_sub = X_train[:, :, feature_idx]\n",
        "    X_val_sub   = X_val[:, :, feature_idx]\n",
        "    X_test_sub  = X_test[:, :, feature_idx]\n",
        "\n",
        "    # Bootstrap sample from training data (with replacement)\n",
        "    indices = np.random.choice(len(X_train_sub), size=len(X_train_sub), replace=True)\n",
        "    X_boot = X_train_sub[indices]\n",
        "    y_reg_boot = y_reg_train[indices]\n",
        "    y_clf_boot = y_clf_train[indices]\n",
        "\n",
        "    # Build and train the model on this bootstrap sample\n",
        "    model_i = build_model(input_dim=feature_subset)\n",
        "    es_cb = EarlyStopping(patience=20, restore_best_weights=True)\n",
        "\n",
        "    model_i.fit(\n",
        "        X_boot, {\"regression\": y_reg_boot, \"classification\": y_clf_boot},\n",
        "        validation_data=(X_val_sub, {\"regression\": y_reg_val, \"classification\": y_clf_val}),\n",
        "        epochs=300, batch_size=256, callbacks=[lr_cb, es_cb], verbose=0\n",
        "    )\n",
        "\n",
        "    # Predict on test set using the same subset of features\n",
        "    pred_reg_i, pred_clf_i = model_i.predict(X_test_sub, verbose=0)\n",
        "    ensemble_preds_reg.append(pred_reg_i.flatten())\n",
        "    ensemble_preds_clf.append(pred_clf_i)\n",
        "\n",
        "# ------------------------------\n",
        "# 7) Aggregate Ensemble Predictions\n",
        "# ------------------------------\n",
        "final_pred_reg = np.mean(np.vstack(ensemble_preds_reg), axis=0)\n",
        "final_pred_clf_prob = np.mean(np.stack(ensemble_preds_clf), axis=0)\n",
        "final_pred_clf = final_pred_clf_prob.argmax(axis=1)\n",
        "\n",
        "# ------------------------------\n",
        "# 8) Evaluate Ensemble Performance\n",
        "# ------------------------------\n",
        "rmse = math.sqrt(mean_squared_error(y_reg_test, final_pred_reg))\n",
        "acc = accuracy_score(y_clf_test, final_pred_clf)\n",
        "bacc = balanced_accuracy_score(y_clf_test, final_pred_clf)\n",
        "\n",
        "print(\"Ensemble Test RMSE:\", rmse)\n",
        "print(\"Ensemble Test Accuracy:\", acc)\n",
        "print(\"Ensemble Test Balanced Accuracy:\", bacc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM5eIaaCK2ht",
        "outputId": "1b05dd7b-2d47-4121-c196-95064bdc700c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes → Train: (2751, 50, 48) Val: (393, 50, 48) Test: (786, 50, 48)\n",
            "Training model 1/100\n",
            "Training model 2/100\n",
            "Training model 3/100\n",
            "Training model 4/100\n",
            "Training model 5/100\n",
            "Training model 6/100\n",
            "Training model 7/100\n",
            "Training model 8/100\n",
            "Training model 9/100\n",
            "Training model 10/100\n",
            "Training model 11/100\n",
            "Training model 12/100\n",
            "Training model 13/100\n",
            "Training model 14/100\n",
            "Training model 15/100\n",
            "Training model 16/100\n",
            "Training model 17/100\n",
            "Training model 18/100\n",
            "Training model 19/100\n",
            "Training model 20/100\n",
            "Training model 21/100\n",
            "Training model 22/100\n",
            "Training model 23/100\n",
            "Training model 24/100\n",
            "Training model 25/100\n",
            "Training model 26/100\n",
            "Training model 27/100\n",
            "Training model 28/100\n",
            "Training model 29/100\n",
            "Training model 30/100\n",
            "Training model 31/100\n",
            "Training model 32/100\n",
            "Training model 33/100\n",
            "Training model 34/100\n",
            "Training model 35/100\n",
            "Training model 36/100\n",
            "Training model 37/100\n",
            "Training model 38/100\n",
            "Training model 39/100\n",
            "Training model 40/100\n",
            "Training model 41/100\n",
            "Training model 42/100\n",
            "Training model 43/100\n",
            "Training model 44/100\n",
            "Training model 45/100\n",
            "Training model 46/100\n",
            "Training model 47/100\n",
            "Training model 48/100\n",
            "Training model 49/100\n",
            "Training model 50/100\n",
            "Training model 51/100\n",
            "Training model 52/100\n",
            "Training model 53/100\n",
            "Training model 54/100\n",
            "Training model 55/100\n",
            "Training model 56/100\n",
            "Training model 57/100\n",
            "Training model 58/100\n",
            "Training model 59/100\n",
            "Training model 60/100\n",
            "Training model 61/100\n",
            "Training model 62/100\n",
            "Training model 63/100\n",
            "Training model 64/100\n",
            "Training model 65/100\n",
            "Training model 66/100\n",
            "Training model 67/100\n",
            "Training model 68/100\n",
            "Training model 69/100\n",
            "Training model 70/100\n",
            "Training model 71/100\n",
            "Training model 72/100\n",
            "Training model 73/100\n",
            "Training model 74/100\n",
            "Training model 75/100\n",
            "Training model 76/100\n",
            "Training model 77/100\n",
            "Training model 78/100\n",
            "Training model 79/100\n",
            "Training model 80/100\n",
            "Training model 81/100\n",
            "Training model 82/100\n",
            "Training model 83/100\n",
            "Training model 84/100\n",
            "Training model 85/100\n",
            "Training model 86/100\n",
            "Training model 87/100\n",
            "Training model 88/100\n",
            "Training model 89/100\n",
            "Training model 90/100\n",
            "Training model 91/100\n",
            "Training model 92/100\n",
            "Training model 93/100\n",
            "Training model 94/100\n",
            "Training model 95/100\n",
            "Training model 96/100\n",
            "Training model 97/100\n",
            "Training model 98/100\n",
            "Training model 99/100\n",
            "Training model 100/100\n",
            "Ensemble Test RMSE: 1.1970801855490854\n",
            "Ensemble Test Accuracy: 0.5330788804071247\n",
            "Ensemble Test Balanced Accuracy: 0.5\n"
          ]
        }
      ]
    }
  ]
}