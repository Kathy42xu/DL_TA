{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kathy42xu/DL_TA/blob/main/Autocoder_on_recommender_system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcPklJ71zLtQ"
      },
      "source": [
        "#Data preperation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii2-PgHwzYPh",
        "outputId": "1411ba86-46e8-4944-9deb-346a2a2fa5a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-11 23:58:07--  https://files.grouplens.org/datasets/movielens/ml-32m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238950008 (228M) [application/zip]\n",
            "Saving to: ‘movielens/ml-32m.zip’\n",
            "\n",
            "movielens/ml-32m.zi 100%[===================>] 227.88M  71.2MB/s    in 3.2s    \n",
            "\n",
            "2025-01-11 23:58:11 (71.2 MB/s) - ‘movielens/ml-32m.zip’ saved [238950008/238950008]\n",
            "\n",
            "Archive:  movielens/ml-32m.zip\n",
            "   creating: movielens/ml-32m/\n",
            "  inflating: movielens/ml-32m/tags.csv  \n",
            "  inflating: movielens/ml-32m/links.csv  \n",
            "  inflating: movielens/ml-32m/README.txt  \n",
            "  inflating: movielens/ml-32m/checksums.txt  \n",
            "  inflating: movielens/ml-32m/ratings.csv  \n",
            "  inflating: movielens/ml-32m/movies.csv  \n",
            "Ratings Data:\n",
            "   userId  movieId  rating  timestamp\n",
            "0       1       17     4.0  944249077\n",
            "1       1       25     1.0  944250228\n",
            "2       1       29     2.0  943230976\n",
            "3       1       30     5.0  944249077\n",
            "4       1       32     5.0  943228858\n",
            "\n",
            "Movies Data:\n",
            "   movieId                               title  \\\n",
            "0        1                    Toy Story (1995)   \n",
            "1        2                      Jumanji (1995)   \n",
            "2        3             Grumpier Old Men (1995)   \n",
            "3        4            Waiting to Exhale (1995)   \n",
            "4        5  Father of the Bride Part II (1995)   \n",
            "\n",
            "                                        genres  \n",
            "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
            "1                   Adventure|Children|Fantasy  \n",
            "2                               Comedy|Romance  \n",
            "3                         Comedy|Drama|Romance  \n",
            "4                                       Comedy  \n",
            "\n",
            "Tags Data:\n",
            "   userId  movieId          tag   timestamp\n",
            "0      22    26479  Kevin Kline  1583038886\n",
            "1      22    79592     misogyny  1581476297\n",
            "2      22   247150   acrophobia  1622483469\n",
            "3      34     2174        music  1249808064\n",
            "4      34     2174        weird  1249808102\n",
            "\n",
            "Links Data:\n",
            "   movieId  imdbId   tmdbId\n",
            "0        1  114709    862.0\n",
            "1        2  113497   8844.0\n",
            "2        3  113228  15602.0\n",
            "3        4  114885  31357.0\n",
            "4        5  113041  11862.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('movielens', exist_ok=True)\n",
        "\n",
        "\n",
        "!wget -O movielens/ml-32m.zip https://files.grouplens.org/datasets/movielens/ml-32m.zip\n",
        "\n",
        "!unzip movielens/ml-32m.zip -d movielens/\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the ratings data\n",
        "ratings = pd.read_csv('movielens/ml-32m/ratings.csv')\n",
        "print(\"Ratings Data:\")\n",
        "print(ratings.head())\n",
        "\n",
        "# Load the movies data\n",
        "movies = pd.read_csv('movielens/ml-32m/movies.csv')\n",
        "print(\"\\nMovies Data:\")\n",
        "print(movies.head())\n",
        "\n",
        "# Load the tags data\n",
        "tags = pd.read_csv('movielens/ml-32m/tags.csv')\n",
        "print(\"\\nTags Data:\")\n",
        "print(tags.head())\n",
        "\n",
        "# Load the links data\n",
        "links = pd.read_csv('movielens/ml-32m/links.csv')\n",
        "print(\"\\nLinks Data:\")\n",
        "print(links.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aROcWuEmzOS9",
        "outputId": "423f6dce-1b0c-403b-ff47-933a3e258ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Amount of data after filtering: 273932\n",
            "      userId  movieId  rating   timestamp  \\\n",
            "2237      22   235509     2.5  1611070726   \n",
            "2238      22   247150     3.0  1622483323   \n",
            "2239      22   278420     4.0  1668895485   \n",
            "2240      22   279412     3.5  1668895505   \n",
            "2241      22   280236     4.0  1674334098   \n",
            "\n",
            "                                    title                   genres  \n",
            "2237              Outside the Wire (2021)   Action|Sci-Fi|Thriller  \n",
            "2238                      Stowaway (2021)             Drama|Sci-Fi  \n",
            "2239  Weird: The Al Yankovic Story (2022)             Comedy|Drama  \n",
            "2240                Enola Holmes 2 (2022)  Adventure|Crime|Mystery  \n",
            "2241                      Spirited (2022)                   Comedy  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load datasets\n",
        "ratings = pd.read_csv('movielens/ml-32m/ratings.csv')\n",
        "movies = pd.read_csv('movielens/ml-32m/movies.csv')\n",
        "\n",
        "# Merge ratings with movies to filter based on titles\n",
        "merged_data = ratings.merge(movies, on=\"movieId\")\n",
        "all_ratings = merged_data[\n",
        "    merged_data['title'].str.endswith(tuple(f\"({year})\" for year in range(2020, 2025)))\n",
        "]\n",
        "\n",
        "# Display filtered data\n",
        "print(f\"Amount of data after filtering: {len(all_ratings)}\")\n",
        "print(all_ratings.head())\n",
        "\n",
        "# Create user-item interaction matrix\n",
        "user_item_matrix = all_ratings.pivot(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "\n",
        "# Split into train and test sets\n",
        "train_data, test_data = train_test_split(user_item_matrix, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhl7cHRAzytg"
      },
      "source": [
        "#Build auto encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-06qa1fz03h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class AutoRec:\n",
        "    def __init__(self, num_items, hidden_neurons, learning_rate, lambda_value):\n",
        "        self.num_items = num_items\n",
        "        self.hidden_neurons = hidden_neurons\n",
        "        self.learning_rate = learning_rate\n",
        "        self.lambda_value = lambda_value\n",
        "\n",
        "        self.input_R = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, self.num_items])\n",
        "        self.input_mask_R = tf.compat.v1.placeholder(dtype=tf.float32, shape=[None, self.num_items])\n",
        "\n",
        "        self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "      with tf.compat.v1.variable_scope(\"AutoRec\", reuse=tf.compat.v1.AUTO_REUSE):\n",
        "        V = tf.compat.v1.get_variable(\"V\", shape=[self.num_items, self.hidden_neurons],\n",
        "                                      initializer=tf.compat.v1.truncated_normal_initializer(mean=0, stddev=0.03))\n",
        "        W = tf.compat.v1.get_variable(\"W\", shape=[self.hidden_neurons, self.num_items],\n",
        "                                      initializer=tf.compat.v1.truncated_normal_initializer(mean=0, stddev=0.03))\n",
        "        mu = tf.compat.v1.get_variable(\"mu\", initializer=tf.zeros(self.hidden_neurons))\n",
        "        b = tf.compat.v1.get_variable(\"b\", initializer=tf.zeros(self.num_items))\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = tf.nn.sigmoid(tf.matmul(self.input_R, V) + mu)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = tf.matmul(self.encoder, W) + b\n",
        "\n",
        "        # Loss\n",
        "        pre_rec_cost = tf.multiply(self.input_R - self.decoder, self.input_mask_R)\n",
        "        rec_cost = tf.reduce_sum(tf.square(pre_rec_cost))\n",
        "        reg_cost = self.lambda_value * 0.5 * (tf.nn.l2_loss(W) + tf.nn.l2_loss(V))\n",
        "\n",
        "        self.loss = rec_cost + reg_cost\n",
        "        self.optimizer = tf.compat.v1.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
        "\n",
        "\n",
        "    def train(self, train_data, mask, epochs, batch_size):\n",
        "        session = tf.compat.v1.Session()\n",
        "        session.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            total_loss = 0\n",
        "            for i in range(0, len(train_data), batch_size):\n",
        "                batch_data = train_data[i:i + batch_size]\n",
        "                batch_mask = mask[i:i + batch_size]\n",
        "                feed_dict = {self.input_R: batch_data, self.input_mask_R: batch_mask}\n",
        "                _, batch_loss = session.run([self.optimizer, self.loss], feed_dict=feed_dict)\n",
        "                total_loss += batch_loss\n",
        "            print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_data)}\")\n",
        "\n",
        "        self.session = session\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        feed_dict = {self.input_R: test_data}\n",
        "        return self.session.run(self.decoder, feed_dict=feed_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eW_TRuGz40L",
        "outputId": "f0b99077-1303-4ccb-b284-725873d54c49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 26.490068384038864\n",
            "Epoch 2, Loss: 12.821944492805994\n",
            "Epoch 3, Loss: 11.010856953514562\n",
            "Epoch 4, Loss: 9.72670793378929\n",
            "Epoch 5, Loss: 8.631821431670222\n",
            "Epoch 6, Loss: 7.528749337237728\n",
            "Epoch 7, Loss: 6.725265046411066\n",
            "Epoch 8, Loss: 6.018965935679301\n",
            "Epoch 9, Loss: 5.430313302049858\n",
            "Epoch 10, Loss: 4.908460137078589\n",
            "Epoch 11, Loss: 4.491645234928988\n",
            "Epoch 12, Loss: 4.083661553094214\n",
            "Epoch 13, Loss: 3.7638386050865233\n",
            "Epoch 14, Loss: 3.448445496388072\n",
            "Epoch 15, Loss: 3.1918452568829885\n",
            "Epoch 16, Loss: 2.9980573808570985\n",
            "Epoch 17, Loss: 2.9115718806473923\n",
            "Epoch 18, Loss: 2.804651219615385\n",
            "Epoch 19, Loss: 2.6664899409303637\n",
            "Epoch 20, Loss: 2.5349965722368504\n",
            "Epoch 21, Loss: 2.4746736670510012\n",
            "Epoch 22, Loss: 2.4151068525508252\n",
            "Epoch 23, Loss: 2.4064883293998687\n",
            "Epoch 24, Loss: 2.4228810613103797\n",
            "Epoch 25, Loss: 2.489017366513797\n",
            "Epoch 26, Loss: 2.545472761553629\n",
            "Epoch 27, Loss: 2.5603888948537143\n",
            "Epoch 28, Loss: 2.5026590223526064\n",
            "Epoch 29, Loss: 2.415405444384949\n",
            "Epoch 30, Loss: 2.3735462698104577\n",
            "Epoch 31, Loss: 2.3741901685746587\n",
            "Epoch 32, Loss: 2.3969491465291495\n",
            "Epoch 33, Loss: 2.4412313836054116\n",
            "Epoch 34, Loss: 2.4378852424280675\n",
            "Epoch 35, Loss: 2.4313794380487392\n",
            "Epoch 36, Loss: 2.364035287340014\n",
            "Epoch 37, Loss: 2.3489519871974944\n",
            "Epoch 38, Loss: 2.3198743221627325\n",
            "Epoch 39, Loss: 2.4085850146841685\n",
            "Epoch 40, Loss: 2.5231930332902706\n",
            "Epoch 41, Loss: 2.5232573391751694\n",
            "Epoch 42, Loss: 2.444596742042805\n",
            "Epoch 43, Loss: 2.38023190596548\n",
            "Epoch 44, Loss: 2.366972744549792\n",
            "Epoch 45, Loss: 2.3958106039101836\n",
            "Epoch 46, Loss: 2.390308593070163\n",
            "Epoch 47, Loss: 2.3767799334951576\n",
            "Epoch 48, Loss: 2.3687494675925693\n",
            "Epoch 49, Loss: 2.4088165506521757\n",
            "Epoch 50, Loss: 2.436879710758339\n",
            "RMSE: 0.8863084353436137, MAE: 0.6074606228826596\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Prepare mask for training\n",
        "train_mask = (train_data > 0).astype(float)\n",
        "\n",
        "# Instantiate and train AutoRec\n",
        "num_items = user_item_matrix.shape[1]\n",
        "hidden_neurons = 500\n",
        "learning_rate = 0.001\n",
        "lambda_value = 0.1\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "autorec = AutoRec(num_items, hidden_neurons, learning_rate, lambda_value)\n",
        "autorec.train(train_data.values, train_mask.values, epochs, batch_size)\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = autorec.predict(test_data.values)\n",
        "\n",
        "# Evaluate\n",
        "test_mask = (test_data > 0).astype(float)\n",
        "true_ratings = test_data.values[test_mask.values > 0]\n",
        "predicted_ratings = test_predictions[test_mask.values > 0]\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
        "mae = mean_absolute_error(true_ratings, predicted_ratings)\n",
        "\n",
        "print(f\"RMSE: {rmse}, MAE: {mae}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1KG6mf3yWOc90cRZFl2Zc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}