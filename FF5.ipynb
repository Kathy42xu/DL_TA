{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1j4vi_Kuc3CuIMD0WYeSjw6E7NK6UmNHs",
      "authorship_tag": "ABX9TyNJ3DnV20PCw7wCS6hzHlES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kathy42xu/DL_TA/blob/main/FF5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data exploration"
      ],
      "metadata": {
        "id": "G02QvuZgtUeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\\n\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"Not a Colab environment, skipping Google Drive mount.\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while mounting Google Drive: {e}\\n\")\n",
        "\n",
        "# --- Define file paths ---\n",
        "ff5_file_path = '/content/drive/MyDrive/Fuqua/FF5.csv'\n",
        "monthly_stock_file_path = '/content/drive/MyDrive/Fuqua/monthly_stock.csv'\n",
        "\n",
        "# --- Load Data ---\n",
        "print(\"--- Loading FF5.csv ---\")\n",
        "try:\n",
        "    df_ff5 = pd.read_csv(ff5_file_path)\n",
        "    print(\"FF5.csv loaded successfully.\")\n",
        "    print(df_ff5.head(3))\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: FF5.csv not found at {ff5_file_path}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"ERROR reading FF5.csv: {e}\")\n",
        "    exit()\n",
        "\n",
        "print(\"\\n--- Loading monthly_stock.csv ---\")\n",
        "try:\n",
        "    df_monthly_stock = pd.read_csv(monthly_stock_file_path)\n",
        "    print(\"monthly_stock.csv loaded successfully.\")\n",
        "    print(df_monthly_stock.head(3))\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: monthly_stock.csv not found at {monthly_stock_file_path}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"ERROR reading monthly_stock.csv: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Prepare monthly_stock Data ---\n",
        "print(\"\\n--- Preparing monthly_stock_df ---\")\n",
        "df_monthly_stock.columns = df_monthly_stock.columns.str.lower()\n",
        "\n",
        "\n",
        "if 'mthret' in df_monthly_stock.columns:\n",
        "    ret_col = 'mthret'\n",
        "elif 'mthretx' in df_monthly_stock.columns:\n",
        "    ret_col = 'mthretx'\n",
        "    print(\"Using 'mthretx' as the return column since 'mthret' was not found.\")\n",
        "else:\n",
        "    print(\"ERROR: Neither 'mthret' nor 'mthretx' found in monthly_stock.csv columns.\")\n",
        "    exit()\n",
        "\n",
        "# Convert return column to numeric, coercing errors to NaN (CRSP specific codes)\n",
        "df_monthly_stock[ret_col] = pd.to_numeric(df_monthly_stock[ret_col], errors='coerce')\n",
        "\n",
        "# Convert 'yyyymm' to datetime period for merging\n",
        "df_monthly_stock['date_period'] = pd.to_datetime(df_monthly_stock['yyyymm'], format='%Y%m').dt.to_period('M')\n",
        "print(f\"Selected return column: {ret_col}\")\n",
        "print(df_monthly_stock[['permno', 'yyyymm', 'date_period', ret_col]].head(3))\n",
        "\n",
        "# --- Prepare FF5 Data ---\n",
        "print(\"\\n--- Preparing FF5_df ---\")\n",
        "df_ff5.columns = df_ff5.columns.str.lower()\n",
        "\n",
        "# Convert 'dateff' (e.g., 19770131) to datetime period for merging\n",
        "try:\n",
        "    df_ff5['date_period'] = pd.to_datetime(df_ff5['dateff'], format='%Y%m%d').dt.to_period('M')\n",
        "except ValueError:\n",
        "    # If 'dateff' is not YYYYMMDD, try other common formats or prompt user\n",
        "    print(f\"Warning: Could not parse 'dateff' as YYYYMMDD. Current head of 'dateff':\\n{df_ff5['dateff'].head()}\")\n",
        "    # Add more robust date parsing if needed, or ensure 'dateff' is consistently YYYYMMDD\n",
        "    # For now, let's assume it is YYYYMMDD as per typical K. French files.\n",
        "    # If it's already YYYYMM (e.g., from WRDS Fama-French), then format='%Y%m'\n",
        "    if str(df_ff5['dateff'].iloc[0]).endswith('28') or str(df_ff5['dateff'].iloc[0]).endswith('29') or \\\n",
        "       str(df_ff5['dateff'].iloc[0]).endswith('30') or str(df_ff5['dateff'].iloc[0]).endswith('31'):\n",
        "        print(\"Assuming 'dateff' is YYYYMMDD based on common month-end values.\")\n",
        "    else:\n",
        "        print(\"Attempting to parse 'dateff' as YYYYMM.\")\n",
        "        df_ff5['date_period'] = pd.to_datetime(df_ff5['dateff'], format='%Y%m').dt.to_period('M')\n",
        "\n",
        "\n",
        "# Ensure 'rf' (risk-free rate) is numeric and in decimal form\n",
        "# Data from K. French's website is often in percent.\n",
        "df_ff5['rf'] = pd.to_numeric(df_ff5['rf'], errors='coerce')\n",
        "if df_ff5['rf'].abs().max() > 0.5 and df_ff5['rf'].abs().max() <=100 : # Heuristic: if max absolute value is > 0.5 (e.g. 1 for 1%), assume it's percent\n",
        "    print(\"Risk-free rate ('rf') in FF5.csv appears to be in percentage, dividing by 100.\")\n",
        "    df_ff5['rf'] = df_ff5['rf'] / 100.0\n",
        "else:\n",
        "    print(\"Risk-free rate ('rf') in FF5.csv appears to be in decimal form.\")\n",
        "\n",
        "print(df_ff5[['dateff', 'date_period', 'rf']].head(3))\n",
        "\n",
        "# --- Merge DataFrames ---\n",
        "print(\"\\n--- Merging monthly stock data with risk-free rates ---\")\n",
        "df_rf_to_merge = df_ff5[['date_period', 'rf']].drop_duplicates(subset=['date_period'])\n",
        "\n",
        "df_merged = pd.merge(df_monthly_stock, df_rf_to_merge, on='date_period', how='left')\n",
        "print(\"Merge complete.\")\n",
        "print(df_merged[['permno', 'yyyymm', 'date_period', ret_col, 'rf']].head(3))\n",
        "\n",
        "# --- Calculate Excess Return ---\n",
        "print(\"\\n--- Calculating Excess Return ---\")\n",
        "df_merged['excess_return'] = df_merged[ret_col] - df_merged['rf']\n",
        "print(\"Excess return calculation complete.\")\n",
        "\n",
        "# --- Display Results and Check for Missing Values ---\n",
        "print(\"\\n--- DataFrame with Excess Return (first 5 rows) ---\")\n",
        "print(df_merged[['permno', 'yyyymm', 'date_period', ret_col, 'rf', 'excess_return']].head())\n",
        "\n",
        "print(\"\\n--- Statistics for Calculated Excess Return ---\")\n",
        "print(df_merged['excess_return'].describe())\n",
        "\n",
        "missing_excess_returns = df_merged['excess_return'].isnull().sum()\n",
        "total_rows = len(df_merged)\n",
        "print(f\"\\nNumber of rows with missing excess_return: {missing_excess_returns} out of {total_rows}\")\n",
        "if missing_excess_returns > 0:\n",
        "    missing_rf_in_merged = df_merged['rf'].isnull().sum()\n",
        "    missing_ret_in_merged = df_merged[ret_col].isnull().sum()\n",
        "    print(f\"  Breakdown: Missing 'rf' after merge: {missing_rf_in_merged}\")\n",
        "    print(f\"             Missing '{ret_col}' (original or after coerce): {missing_ret_in_merged}\")\n",
        "    print(\"  This could be due to non-overlapping date ranges or original missing data.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imUu0pMAvF-U",
        "outputId": "f3eaf6c7-2483-4c44-918a-9627ddc89573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "\n",
            "--- Loading FF5.csv ---\n",
            "FF5.csv loaded successfully.\n",
            "    mktrf     smb     hml     rmw     cma      rf     umd    dateff\n",
            "0 -0.0405  0.0590  0.0427 -0.0051  0.0197  0.0036  0.0400  19770131\n",
            "1 -0.0194  0.0107  0.0047 -0.0016 -0.0022  0.0035  0.0036  19770228\n",
            "2 -0.0137  0.0131  0.0109 -0.0030 -0.0006  0.0038  0.0055  19770331\n",
            "\n",
            "--- Loading monthly_stock.csv ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-802fcfccf405>:33: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_monthly_stock = pd.read_csv(monthly_stock_file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "monthly_stock.csv loaded successfully.\n",
            "   hdrcusip    mthcaldt  permno  permco  siccd  yyyymm  mthprc    mthret  \\\n",
            "0  00080010  1977-01-31   10006   22156   3743  197701  35.625  0.014235   \n",
            "1  00147610  1977-01-31   10014   22157   3714  197701   4.375 -0.027778   \n",
            "2  00074210  1977-01-31   10050      13   3448  197701  11.000  0.173333   \n",
            "\n",
            "    mthretx    mthvol    cusip ticker primaryexch  shrout  \n",
            "0  0.014235  129300.0    80010    ACF           N  8675.0  \n",
            "1 -0.027778  204400.0   147610     AJ           N  5019.0  \n",
            "2  0.173333       NaN  2475610   ABLD           Q   755.0  \n",
            "\n",
            "--- Preparing monthly_stock_df ---\n",
            "Selected return column: mthret\n",
            "   permno  yyyymm date_period    mthret\n",
            "0   10006  197701     1977-01  0.014235\n",
            "1   10014  197701     1977-01 -0.027778\n",
            "2   10050  197701     1977-01  0.173333\n",
            "\n",
            "--- Preparing FF5_df ---\n",
            "Risk-free rate ('rf') in FF5.csv appears to be in decimal form.\n",
            "     dateff date_period      rf\n",
            "0  19770131     1977-01  0.0036\n",
            "1  19770228     1977-02  0.0035\n",
            "2  19770331     1977-03  0.0038\n",
            "\n",
            "--- Merging monthly stock data with risk-free rates ---\n",
            "Merge complete.\n",
            "   permno  yyyymm date_period    mthret      rf\n",
            "0   10006  197701     1977-01  0.014235  0.0036\n",
            "1   10014  197701     1977-01 -0.027778  0.0036\n",
            "2   10050  197701     1977-01  0.173333  0.0036\n",
            "\n",
            "--- Calculating Excess Return ---\n",
            "Excess return calculation complete.\n",
            "\n",
            "--- DataFrame with Excess Return (first 5 rows) ---\n",
            "   permno  yyyymm date_period    mthret      rf  excess_return\n",
            "0   10006  197701     1977-01  0.014235  0.0036       0.010635\n",
            "1   10014  197701     1977-01 -0.027778  0.0036      -0.031378\n",
            "2   10050  197701     1977-01  0.173333  0.0036       0.169733\n",
            "3   10057  197701     1977-01  0.236842  0.0036       0.233242\n",
            "4   10058  197701     1977-01 -0.240000  0.0036      -0.243600\n",
            "\n",
            "--- Statistics for Calculated Excess Return ---\n",
            "count    3.726023e+06\n",
            "mean     6.774702e-03\n",
            "std      1.839996e-01\n",
            "min     -1.012400e+00\n",
            "25%     -6.520000e-02\n",
            "50%     -2.200000e-03\n",
            "75%      6.237300e-02\n",
            "max      2.399660e+01\n",
            "Name: excess_return, dtype: float64\n",
            "\n",
            "Number of rows with missing excess_return: 9591 out of 3735614\n",
            "  Breakdown: Missing 'rf' after merge: 0\n",
            "             Missing 'mthret' (original or after coerce): 9591\n",
            "  This could be due to non-overlapping date ranges or original missing data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FF 5"
      ],
      "metadata": {
        "id": "M7WVPgr8kbT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from scipy.stats.mstats import winsorize # For diagnostic winsorization\n",
        "import os\n",
        "\n",
        "# --- 1. Mount Google Drive (if files are in Drive) ---\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Google Drive mounted successfully.\\n\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"Not a Colab environment, skipping Google Drive mount.\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while mounting Google Drive: {e}\\n\")\n",
        "    print(\"Please ensure you are in a Google Colab environment and have authorized Drive access.\\n\")\n",
        "\n",
        "# --- 2. Define file paths ---\n",
        "ff5_file_path = '/content/drive/MyDrive/Fuqua/FF5.csv'\n",
        "monthly_stock_file_path = '/content/drive/MyDrive/Fuqua/monthly_stock.csv'\n",
        "\n",
        "# --- 3. Load and Prepare Data ---\n",
        "print(\"--- Loading and Preparing Data ---\")\n",
        "try:\n",
        "    df_ff5_raw = pd.read_csv(ff5_file_path)\n",
        "    df_monthly_stock_raw = pd.read_csv(monthly_stock_file_path)\n",
        "    print(\"Raw CSV files loaded.\")\n",
        "\n",
        "    # Prepare monthly_stock_df\n",
        "    df_monthly_stock = df_monthly_stock_raw.copy()\n",
        "    df_monthly_stock.columns = df_monthly_stock.columns.str.lower() # Ensure lowercase columns\n",
        "\n",
        "    if 'siccd' not in df_monthly_stock.columns:\n",
        "        print(\"WARNING: 'siccd' column not found in monthly_stock.csv. Cannot filter financial firms by SIC code.\")\n",
        "        df_monthly_stock['siccd'] = np.nan # Add dummy to prevent errors if used later\n",
        "    else:\n",
        "        df_monthly_stock['siccd'] = pd.to_numeric(df_monthly_stock['siccd'], errors='coerce')\n",
        "\n",
        "    if 'mthret' in df_monthly_stock.columns:\n",
        "        ret_col = 'mthret'\n",
        "    elif 'mthretx' in df_monthly_stock.columns:\n",
        "        ret_col = 'mthretx'\n",
        "        print(\"Using 'mthretx' as the return column.\")\n",
        "    else:\n",
        "        raise ValueError(\"Return column ('mthret' or 'mthretx') not found in monthly_stock.csv.\")\n",
        "    df_monthly_stock[ret_col] = pd.to_numeric(df_monthly_stock[ret_col], errors='coerce')\n",
        "    df_monthly_stock['date_period'] = pd.to_datetime(df_monthly_stock['yyyymm'], format='%Y%m').dt.to_period('M')\n",
        "    print(\"Monthly stock data pre-processing done.\")\n",
        "\n",
        "    # Prepare FF5_df\n",
        "    df_ff5 = df_ff5_raw.copy()\n",
        "    df_ff5.columns = df_ff5.columns.str.lower()\n",
        "    try:\n",
        "        df_ff5['date_period'] = pd.to_datetime(df_ff5['dateff'], format='%Y%m%d').dt.to_period('M')\n",
        "    except ValueError:\n",
        "        print(\"Warning: Could not parse 'dateff' as YYYYMMDD. Trying YYYYMM.\")\n",
        "        df_ff5['date_period'] = pd.to_datetime(df_ff5['dateff'], format='%Y%m').dt.to_period('M')\n",
        "\n",
        "    df_ff5['rf'] = pd.to_numeric(df_ff5['rf'], errors='coerce')\n",
        "    # Check if RF is in percentage (heuristic: values typically between 0 and 15 for monthly percent)\n",
        "    if df_ff5['rf'].abs().max() > 0.5 and df_ff5['rf'].abs().max() < 15 : # Adjust threshold if needed\n",
        "        print(\"Risk-free rate ('rf') in FF5.csv appears to be in percentage, dividing by 100.\")\n",
        "        df_ff5['rf'] = df_ff5['rf'] / 100.0\n",
        "    else:\n",
        "        print(\"Risk-free rate ('rf') in FF5.csv assumed to be in decimal form.\")\n",
        "    print(\"FF5 data pre-processing done.\")\n",
        "\n",
        "    # Merge for excess return calculation\n",
        "    df_rf_to_merge = df_ff5[['date_period', 'rf']].drop_duplicates(subset=['date_period'])\n",
        "    # Select necessary columns from monthly_stock to avoid duplicate columns if script re-run\n",
        "    cols_to_carry = ['permno', 'date_period', ret_col, 'siccd']\n",
        "    existing_cols_to_carry = [col for col in cols_to_carry if col in df_monthly_stock.columns]\n",
        "    df_merged = pd.merge(df_monthly_stock[existing_cols_to_carry], df_rf_to_merge, on='date_period', how='left')\n",
        "    df_merged['excess_return'] = df_merged[ret_col] - df_merged['rf']\n",
        "    print(\"Excess return calculated.\")\n",
        "\n",
        "    # Merge with FF5 factors\n",
        "    factor_columns = ['mktrf', 'smb', 'hml', 'rmw', 'cma']\n",
        "    df_ff5_factors = df_ff5[['date_period'] + factor_columns].copy()\n",
        "    for factor in factor_columns:\n",
        "        df_ff5_factors[factor] = pd.to_numeric(df_ff5_factors[factor], errors='coerce')\n",
        "        # Check if factors are in percentage\n",
        "        if df_ff5_factors[factor].abs().max() > 1 and df_ff5_factors[factor].abs().max() < 50: # Heuristic for monthly factor returns\n",
        "            print(f\"Factor '{factor}' appears to be in percentage, dividing by 100.\")\n",
        "            df_ff5_factors[factor] = df_ff5_factors[factor] / 100.0\n",
        "        else:\n",
        "            print(f\"Factor '{factor}' assumed to be in decimal form.\")\n",
        "\n",
        "\n",
        "    final_df_unfiltered = pd.merge(df_merged, df_ff5_factors, on='date_period', how='inner')\n",
        "    final_df_unfiltered.dropna(subset=['excess_return'] + factor_columns, inplace=True)\n",
        "    final_df_unfiltered['year'] = final_df_unfiltered['date_period'].dt.year\n",
        "    print(\"Final unfiltered DataFrame created.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: One of the CSV files not found. Please check paths:\\nFF5: {ff5_file_path}\\nMonthly Stock: {monthly_stock_file_path}\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"ERROR during data loading and preparation: {e}\")\n",
        "    raise # Re-raise the exception to see the full traceback\n",
        "\n",
        "# --- VERIFY DATA SCALES ---\n",
        "print(\"\\n--- Verifying Data Scales (Unfiltered Data) ---\")\n",
        "print(\"Excess Return (sample):\")\n",
        "print(final_df_unfiltered['excess_return'].describe())\n",
        "for factor in factor_columns:\n",
        "    print(f\"\\nFactor {factor} (sample):\")\n",
        "    print(final_df_unfiltered[factor].describe())\n",
        "\n",
        "# --- Apply Common Filters ---\n",
        "print(\"\\n--- Applying Filters ---\")\n",
        "# Filter 1: Exclude financial firms (SIC codes 6000-6999)\n",
        "if 'siccd' in final_df_unfiltered.columns:\n",
        "    final_df = final_df_unfiltered[~final_df_unfiltered['siccd'].between(6000, 6999)].copy()\n",
        "    print(f\"Excluded financial firms (SIC 6000-6999). Rows from {len(final_df_unfiltered)} to {len(final_df)}\")\n",
        "else:\n",
        "    final_df = final_df_unfiltered.copy()\n",
        "    print(\"SICCD column not found, could not filter financial firms.\")\n",
        "\n",
        "print(f\"Final DataFrame for analysis has {len(final_df)} rows after filtering.\")\n",
        "\n",
        "\n",
        "# --- 4. Define In-sample and Out-of-sample Periods ---\n",
        "train_start_year = 1977\n",
        "train_end_year = 2006\n",
        "test_start_year = 2007\n",
        "# Use the actual max year from the filtered data or 2023, whichever is earlier\n",
        "data_max_year = final_df['year'].max() if not final_df.empty else train_end_year # Default to train_end_year if df is empty\n",
        "test_end_year = min(data_max_year, 2023)\n",
        "\n",
        "\n",
        "train_df_all_stocks = final_df[(final_df['year'] >= train_start_year) & (final_df['year'] <= train_end_year)]\n",
        "test_df_all_stocks = final_df[(final_df['year'] >= test_start_year) & (final_df['year'] <= test_end_year)]\n",
        "\n",
        "if not train_df_all_stocks.empty:\n",
        "    print(f\"\\nTraining period (after filtering): {train_df_all_stocks['date_period'].min()} to {train_df_all_stocks['date_period'].max()}, {len(train_df_all_stocks)} observations\")\n",
        "else:\n",
        "    print(\"\\nTraining DataFrame is empty AFTER FILTERS.\")\n",
        "\n",
        "if not test_df_all_stocks.empty:\n",
        "    print(f\"Testing period (after filtering): {test_df_all_stocks['date_period'].min()} to {test_df_all_stocks['date_period'].max()}, {len(test_df_all_stocks)} observations\")\n",
        "else:\n",
        "    print(\"Testing DataFrame is empty AFTER FILTERS.\")\n",
        "\n",
        "if train_df_all_stocks.empty or test_df_all_stocks.empty:\n",
        "    print(\"ERROR: Training or testing DataFrame is empty. Check date ranges, data availability, and filters.\")\n",
        "    exit()\n",
        "\n",
        "# --- 5. Perform Time-Series FF5 Regression and Collect Errors ---\n",
        "in_sample_actuals_all = []\n",
        "in_sample_predictions_all = []\n",
        "oos_actuals_all = []\n",
        "oos_predictions_all = []\n",
        "\n",
        "firm_level_in_sample_maes = []\n",
        "firm_level_oos_maes = []\n",
        "\n",
        "# Store in-sample R-squared from individual time-series regressions\n",
        "firm_level_in_sample_r_squareds = []\n",
        "\n",
        "unique_permnos = train_df_all_stocks['permno'].unique()\n",
        "min_obs_for_regression = 60\n",
        "\n",
        "print(f\"\\nStarting FF5 regressions for {len(unique_permnos)} unique permnos (post-filtering)...\")\n",
        "processed_count = 0\n",
        "\n",
        "for i, permno_val in enumerate(unique_permnos):\n",
        "    if (i + 1) % 500 == 0: # Print progress every 500 stocks\n",
        "        print(f\"Processing permno {i+1}/{len(unique_permnos)}...\")\n",
        "\n",
        "    stock_train_data = train_df_all_stocks[train_df_all_stocks['permno'] == permno_val].copy()\n",
        "    stock_test_data = test_df_all_stocks[test_df_all_stocks['permno'] == permno_val].copy()\n",
        "\n",
        "    if len(stock_train_data) < min_obs_for_regression:\n",
        "        continue\n",
        "\n",
        "    Y_train = stock_train_data['excess_return']\n",
        "    X_train_factors = stock_train_data[factor_columns]\n",
        "    X_train_reg = sm.add_constant(X_train_factors) # Adds a 'const' column\n",
        "\n",
        "    try:\n",
        "        model = sm.OLS(Y_train, X_train_reg).fit()\n",
        "        firm_level_in_sample_r_squareds.append(model.rsquared)\n",
        "\n",
        "        # In-sample predictions and errors\n",
        "        in_sample_predictions_stock = model.predict(X_train_reg)\n",
        "        in_sample_actuals_all.extend(Y_train.tolist())\n",
        "        in_sample_predictions_all.extend(in_sample_predictions_stock.tolist())\n",
        "\n",
        "        # MAE Calculation (Original, without winsorization by default)\n",
        "        current_in_sample_mae = mean_absolute_error(Y_train, in_sample_predictions_stock)\n",
        "        firm_level_in_sample_maes.append(current_in_sample_mae)\n",
        "\n",
        "\n",
        "        # Out-of-sample predictions and errors\n",
        "        if not stock_test_data.empty and len(stock_test_data['excess_return']) > 0:\n",
        "            Y_test_actual = stock_test_data['excess_return']\n",
        "            X_test_factors = stock_test_data[factor_columns]\n",
        "            X_test_reg = sm.add_constant(X_test_factors, has_constant='add')\n",
        "\n",
        "            # Ensure X_test_reg has the same columns in the same order as X_train_reg\n",
        "            # This handles cases where a factor might be all NaN in a small test set for a stock (though unlikely for FF factors)\n",
        "            X_test_reg_aligned = X_test_reg.reindex(columns=X_train_reg.columns, fill_value=0)\n",
        "            oos_predictions_stock = model.predict(X_test_reg_aligned)\n",
        "\n",
        "            oos_actuals_all.extend(Y_test_actual.tolist())\n",
        "            oos_predictions_all.extend(oos_predictions_stock.tolist())\n",
        "\n",
        "            current_oos_mae = mean_absolute_error(Y_test_actual, oos_predictions_stock)\n",
        "            firm_level_oos_maes.append(current_oos_mae)\n",
        "\n",
        "        processed_count +=1\n",
        "    except Exception as e:\n",
        "        # print(f\"Could not run regression or predict for permno {permno_val}: {e}\")\n",
        "        continue\n",
        "\n",
        "print(f\"Finished FF5 regressions. Successfully processed {processed_count} firms.\")\n",
        "\n",
        "# --- 6. Calculate Pooled RMSE and Average of Firm-Level MAEs ---\n",
        "print(\"\\n--- FF5 Model Performance Metrics (as per Graph.pdf Section 3.2.3 definitions) ---\")\n",
        "\n",
        "# In-sample Metrics\n",
        "if in_sample_actuals_all:\n",
        "    in_sample_actuals_np = np.array(in_sample_actuals_all)\n",
        "    in_sample_predictions_np = np.array(in_sample_predictions_all)\n",
        "    pooled_in_sample_rmse = np.sqrt(mean_squared_error(in_sample_actuals_np, in_sample_predictions_np))\n",
        "    avg_firm_level_in_sample_mae = np.mean(firm_level_in_sample_maes) if firm_level_in_sample_maes else np.nan\n",
        "    avg_firm_level_in_sample_r_squared = np.mean(firm_level_in_sample_r_squareds) if firm_level_in_sample_r_squareds else np.nan\n",
        "    #??? definition of R^2\n",
        "\n",
        "\n",
        "    print(f\"\\nIn-sample Pooled RMSE: {pooled_in_sample_rmse:.4f}\")\n",
        "    print(f\"In-sample Average of Firm-Level MAEs (Graph.pdf 'MAPE'): {avg_firm_level_in_sample_mae:.4f}\")\n",
        "    print(f\"In-sample Average of Firm-Level Time-Series R-squared: {avg_firm_level_in_sample_r_squared:.4f}\") # Added this\n",
        "else:\n",
        "    print(\"\\nNo in-sample results to report (no firms met regression criteria).\")\n",
        "\n",
        "# Out-of-sample Metrics\n",
        "if oos_actuals_all:\n",
        "    oos_actuals_np = np.array(oos_actuals_all)\n",
        "    oos_predictions_np = np.array(oos_predictions_all)\n",
        "    pooled_oos_rmse = np.sqrt(mean_squared_error(oos_actuals_np, oos_predictions_np))\n",
        "    avg_firm_level_oos_mae = np.mean(firm_level_oos_maes) if firm_level_oos_maes else np.nan\n",
        "\n",
        "    print(f\"\\nOut-of-sample Pooled RMSE: {pooled_oos_rmse:.4f}\")\n",
        "    print(f\"Out-of-sample Average of Firm-Level MAEs (Graph.pdf 'MAPE'): {avg_firm_level_oos_mae:.4f}\")\n",
        "\n",
        "    # Calculate the Pooled Out-of-Sample R-squared (vs. zero forecast, like ML.pdf Eq 19)\n",
        "    ssr_oos_pooled = np.sum((oos_actuals_np - oos_predictions_np)**2)\n",
        "    sst_zero_benchmark_oos_pooled = np.sum(oos_actuals_np**2)\n",
        "    if sst_zero_benchmark_oos_pooled == 0: # Avoid division by zero\n",
        "        r_squared_oos_pooled_ml_style = np.nan\n",
        "    else:\n",
        "        r_squared_oos_pooled_ml_style = 1 - (ssr_oos_pooled / sst_zero_benchmark_oos_pooled)\n",
        "    print(f\"Pooled Out-of-Sample R-squared (vs. zero forecast, ML.pdf Eq 19 style): {r_squared_oos_pooled_ml_style:.4f}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo out-of-sample results to report (no firms had test data or met regression criteria).\")\n",
        "\n",
        "# --- Optional: Sanity check distribution of MAEs ---\n",
        "if firm_level_oos_maes:\n",
        "    print(\"\\n--- Distribution of Firm-Level Out-of-Sample MAEs ---\")\n",
        "    print(pd.Series(firm_level_oos_maes).describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]))\n",
        "if firm_level_in_sample_maes:\n",
        "    print(\"\\n--- Distribution of Firm-Level In-Sample MAEs ---\")\n",
        "    print(pd.Series(firm_level_in_sample_maes).describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C196IOx88r_",
        "outputId": "cf416a78-9cb4-402b-dc65-ba81ccbe701f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n",
            "\n",
            "--- Loading and Preparing Data ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e3a10ceb0242>:28: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_monthly_stock_raw = pd.read_csv(monthly_stock_file_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw CSV files loaded.\n",
            "Monthly stock data pre-processing done.\n",
            "Risk-free rate ('rf') in FF5.csv assumed to be in decimal form.\n",
            "FF5 data pre-processing done.\n",
            "Excess return calculated.\n",
            "Factor 'mktrf' assumed to be in decimal form.\n",
            "Factor 'smb' assumed to be in decimal form.\n",
            "Factor 'hml' assumed to be in decimal form.\n",
            "Factor 'rmw' assumed to be in decimal form.\n",
            "Factor 'cma' assumed to be in decimal form.\n",
            "Final unfiltered DataFrame created.\n",
            "\n",
            "--- Verifying Data Scales (Unfiltered Data) ---\n",
            "Excess Return (sample):\n",
            "count    3.726023e+06\n",
            "mean     6.774702e-03\n",
            "std      1.839996e-01\n",
            "min     -1.012400e+00\n",
            "25%     -6.520000e-02\n",
            "50%     -2.200000e-03\n",
            "75%      6.237300e-02\n",
            "max      2.399660e+01\n",
            "Name: excess_return, dtype: float64\n",
            "\n",
            "Factor mktrf (sample):\n",
            "count    3.726023e+06\n",
            "mean     6.584337e-03\n",
            "std      4.530174e-02\n",
            "min     -2.324000e-01\n",
            "25%     -1.970000e-02\n",
            "50%      1.090000e-02\n",
            "75%      3.560000e-02\n",
            "max      1.365000e-01\n",
            "Name: mktrf, dtype: float64\n",
            "\n",
            "Factor smb (sample):\n",
            "count    3.726023e+06\n",
            "mean     1.234448e-03\n",
            "std      3.005195e-02\n",
            "min     -1.532000e-01\n",
            "25%     -1.650000e-02\n",
            "50%      5.000000e-04\n",
            "75%      1.900000e-02\n",
            "max      1.828000e-01\n",
            "Name: smb, dtype: float64\n",
            "\n",
            "Factor hml (sample):\n",
            "count    3.726023e+06\n",
            "mean     2.448073e-03\n",
            "std      3.159636e-02\n",
            "min     -1.388000e-01\n",
            "25%     -1.540000e-02\n",
            "50%      1.100000e-03\n",
            "75%      1.780000e-02\n",
            "max      1.280000e-01\n",
            "Name: hml, dtype: float64\n",
            "\n",
            "Factor rmw (sample):\n",
            "count    3.726023e+06\n",
            "mean     3.911189e-03\n",
            "std      2.478373e-02\n",
            "min     -1.865000e-01\n",
            "25%     -7.600000e-03\n",
            "50%      3.600000e-03\n",
            "75%      1.420000e-02\n",
            "max      1.307000e-01\n",
            "Name: rmw, dtype: float64\n",
            "\n",
            "Factor cma (sample):\n",
            "count    3.726023e+06\n",
            "mean     2.674343e-03\n",
            "std      2.131249e-02\n",
            "min     -7.200000e-02\n",
            "25%     -1.020000e-02\n",
            "50%      8.000000e-04\n",
            "75%      1.490000e-02\n",
            "max      9.070000e-02\n",
            "Name: cma, dtype: float64\n",
            "\n",
            "--- Applying Filters ---\n",
            "Excluded financial firms (SIC 6000-6999). Rows from 3726023 to 2724111\n",
            "Final DataFrame for analysis has 2724111 rows after filtering.\n",
            "\n",
            "Training period (after filtering): 1977-01 to 2006-12, 1867373 observations\n",
            "Testing period (after filtering): 2007-01 to 2023-12, 851980 observations\n",
            "\n",
            "Starting FF5 regressions for 18114 unique permnos (post-filtering)...\n",
            "Processing permno 500/18114...\n",
            "Processing permno 1000/18114...\n",
            "Processing permno 1500/18114...\n",
            "Processing permno 2000/18114...\n",
            "Processing permno 2500/18114...\n",
            "Processing permno 3000/18114...\n",
            "Processing permno 3500/18114...\n",
            "Processing permno 4000/18114...\n",
            "Processing permno 4500/18114...\n",
            "Processing permno 5000/18114...\n",
            "Processing permno 5500/18114...\n",
            "Processing permno 6000/18114...\n",
            "Processing permno 6500/18114...\n",
            "Processing permno 7000/18114...\n",
            "Processing permno 7500/18114...\n",
            "Processing permno 8000/18114...\n",
            "Processing permno 8500/18114...\n",
            "Processing permno 9000/18114...\n",
            "Processing permno 9500/18114...\n",
            "Processing permno 10000/18114...\n",
            "Processing permno 10500/18114...\n",
            "Processing permno 11000/18114...\n",
            "Processing permno 11500/18114...\n",
            "Processing permno 12000/18114...\n",
            "Processing permno 12500/18114...\n",
            "Processing permno 13000/18114...\n",
            "Processing permno 13500/18114...\n",
            "Processing permno 14000/18114...\n",
            "Processing permno 14500/18114...\n",
            "Processing permno 15000/18114...\n",
            "Processing permno 15500/18114...\n",
            "Processing permno 16000/18114...\n",
            "Processing permno 16500/18114...\n",
            "Processing permno 17000/18114...\n",
            "Processing permno 17500/18114...\n",
            "Processing permno 18000/18114...\n",
            "Finished FF5 regressions. Successfully processed 10621 firms.\n",
            "\n",
            "--- FF5 Model Performance Metrics (as per Graph.pdf Section 3.2.3 definitions) ---\n",
            "\n",
            "In-sample Pooled RMSE: 0.1743\n",
            "In-sample Average of Firm-Level MAEs (Graph.pdf 'MAPE'): 0.1159\n",
            "In-sample Average of Firm-Level Time-Series R-squared: 0.1904\n",
            "\n",
            "Out-of-sample Pooled RMSE: 0.1613\n",
            "Out-of-sample Average of Firm-Level MAEs (Graph.pdf 'MAPE'): 0.1055\n",
            "Pooled Out-of-Sample R-squared (vs. zero forecast, ML.pdf Eq 19 style): 0.0689\n",
            "\n",
            "--- Distribution of Firm-Level Out-of-Sample MAEs ---\n",
            "count    3573.000000\n",
            "mean        0.105465\n",
            "std         0.056782\n",
            "min         0.000354\n",
            "1%          0.018426\n",
            "5%          0.039399\n",
            "25%         0.064789\n",
            "50%         0.093367\n",
            "75%         0.133302\n",
            "95%         0.212163\n",
            "99%         0.284675\n",
            "max         0.551396\n",
            "dtype: float64\n",
            "\n",
            "--- Distribution of Firm-Level In-Sample MAEs ---\n",
            "count    10621.000000\n",
            "mean         0.115893\n",
            "std          0.051610\n",
            "min          0.023959\n",
            "1%           0.036226\n",
            "5%           0.048624\n",
            "25%          0.076881\n",
            "50%          0.109100\n",
            "75%          0.145342\n",
            "95%          0.207752\n",
            "99%          0.265215\n",
            "max          0.607393\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}